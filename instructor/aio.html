<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Overview of Structural MRI (Pre)processing and Neuroimaging Analysis: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Overview of Structural MRI (Pre)processing and Neuroimaging Analysis
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Overview of Structural MRI (Pre)processing and Neuroimaging Analysis
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Overview of Structural MRI (Pre)processing and Neuroimaging Analysis
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-Image_Modalities.html">1. sMRI Acquisition and Modalities</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-Image_Cleanup.html">2. sMRI Clean-up</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-Image_Spatial_Normalization.html">3. sMRI Spatial Normalization</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-Image_Quantification.html">4. sMRI Segmentation and Parcellation</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-Image_QC.html">5. sMRI Quality Control</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-Statistical_Analysis.html">6. sMRI Statistical Analysis</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-Reproducibility.html">7. sMRI Analysis: Reproducibility Considerations</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-Image_Modalities"><p>Content from <a href="01-Image_Modalities.html">sMRI Acquisition and Modalities</a></p>
<hr>
<p>Last updated on 2025-02-26 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/01-Image_Modalities.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How is a structural MR image acquired?</li>
<li>What anatomical features do different modalities capture?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Visualize and understand differences in T1,T2,PD/FLAIR weighted
images.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_1/Course_flow_1.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="image-acquisition">Image acquisition<a class="anchor" aria-label="anchor" href="#image-acquisition"></a>
</h2>
<hr class="half-width">
<ol style="list-style-type: decimal">
<li><p>The acquisition starts with application of strong magnetic field
B<sub>0</sub> (e.g. 1.5 or 3.0 Tesla &gt; 10000x earth’s magnetic field)
which forces the hydrogen nuclei of the abundant water molecules in soft
tissues in the body to align with the field. You can think of hydrogen
nuclei as tiny magnets of their own.</p></li>
<li><p>Then the scanner applies a radio-frequency (RF) (i.e. excitation)
pulse which tilts these nuclei from their alignment along B<sub>0</sub>.
The nuclei then <em>precess</em> back to the alignment. The
<em>precessing</em> nuclei emit a signal, which is registered by the
receiver coils in the scanner.</p></li>
<li><p>This signal has two components: 1) <em>Longitudinal</em> (z-axis
along the scanner’s magnetic field) and 2) <em>Transverse</em> (xy-plane
orthogonal to the scanner’s magnetic field).</p></li>
<li><p>Initially the longitudinal signal is weak as most nuclei are
tilted away from the z-axis. However this signal grows as nuclei
realign. The <em>time constant</em> that dictates the speed of
re-alignment is denoted by <em>T1</em>.</p></li>
<li><p>Initially the transverse signal is strong as most nuclei are in
phase <em>coherence</em>. The signal decays as the nuclei dephase as
they realign. This decay is denoted by the <em>T2 time
constant</em>.</p></li>
<li><p>The tissue specific differences in T1 and T2 relaxation times is
what enables us to <em>see</em> anatomy from image contrast. The final
image contrast depends on when you <em>listen</em> to the signal (design
parameter: echo time (TE)) and how fast you repeat the
<em>tilt-relax</em> process i.e. RF pulse frequency (design parameter:
repetition time (TR)).</p></li>
</ol></section><section><h2 class="section-heading" id="t1-and-t2-relaxation">T1 and T2 relaxation<a class="anchor" aria-label="anchor" href="#t1-and-t2-relaxation"></a>
</h2>
<hr class="half-width">
<p>Here we see signal from two different tissues as the nuclei are
tilted and realigned. The figure on the left shows a single nucleus
(i.e. tiny magnet) being tilted away and then precessing back to the the
initial alighment along B<sub>0</sub>. The figure on the right shows the
corresponding registered T1 and T2 signal profiles for two different
“tissues”. The difference in their signal intensities results in the
image contrast.</p>
<figure><img src="https://user-images.githubusercontent.com/7978607/112332334-08750c80-8c90-11eb-90fc-33956c037a1c.gif" alt="MR_relax" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="brain-tissue-comparison">Brain tissue comparison<a class="anchor" aria-label="anchor" href="#brain-tissue-comparison"></a>
</h2>
<hr class="half-width">
<p>The dotted-black line represents the epoch when you “listen” to the
signal (i.e. echo time or TE).</p>
<p><img src="../fig/episode_1/relax_tissue_contrast.png" alt="relax_tissue_contrast" class="figure">)</p>
</section><section><h2 class="section-heading" id="t1w-t2w-and-pd-acquisition">T1w, T2w, and PD acquisition<a class="anchor" aria-label="anchor" href="#t1w-t2w-and-pd-acquisition"></a>
</h2>
<hr class="half-width">
<table class="table">
<colgroup>
<col width="14%">
<col width="45%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th align="center"></th>
<th align="center">TE short</th>
<th align="center">TE long (~ T2 of tissue of interest)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center"><strong>TR short (~ T1 of tissue of
interest)</strong></td>
<td align="center">T1w</td>
<td align="center">-</td>
</tr>
<tr class="even">
<td align="center"><strong>TR long</strong></td>
<td align="center">Proton Density (PD)</td>
<td align="center">T2w</td>
</tr>
</tbody>
</table>
<p><em>Note</em>: More recently, the FLAIR (Fluid Attenuated Inversion
Recovery) sequence has replaced the PD image. FLAIR images are
T2-weighted with the CSF signal suppressed.</p>
<div id="pulse-sequence-parameters-and-image-contrast" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="pulse-sequence-parameters-and-image-contrast" class="callout-inner">
<h3 class="callout-title">pulse sequence parameters and image contrast</h3>
<div class="callout-content">
<p>What are the two basic pulse sequence parameters that impact T1w and
T2w image contrasts? Which one is larger?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Repetition time (TR) and echo time (TE) are the two pulse sequence
parameters that dictate the T1w and T2w image contrasts. TR &gt; TE.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="t1-and-t2-relaxation-times-for-various-tissues">T1 and T2 relaxation times for various tissues<a class="anchor" aria-label="anchor" href="#t1-and-t2-relaxation-times-for-various-tissues"></a>
</h3>
<table class="table">
<colgroup>
<col width="14%">
<col width="45%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th align="center"></th>
<th align="center">T1 (ms)</th>
<th align="center">T2 (ms)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Bones</td>
<td align="center">500</td>
<td align="center">50</td>
</tr>
<tr class="even">
<td align="center">CSF</td>
<td align="center">4000</td>
<td align="center">500</td>
</tr>
<tr class="odd">
<td align="center">Grey Matter</td>
<td align="center">1300</td>
<td align="center">110</td>
</tr>
<tr class="even">
<td align="center">White Matter</td>
<td align="center">800</td>
<td align="center">80</td>
</tr>
</tbody>
</table>
<div id="tissue-type-and-image-contrast" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="tissue-type-and-image-contrast" class="callout-inner">
<h3 class="callout-title">Tissue type and image contrast</h3>
<div class="callout-content">
<p>In the T1w image, which one is brighter: White matter, Grey Matter,
or CSF?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>White Matter (i.e. axonal tracts)</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="t1w-t2w-image-contrasts">T1w, T2w image contrasts<a class="anchor" aria-label="anchor" href="#t1w-t2w-image-contrasts"></a>
</h3>
<table class="table">
<colgroup>
<col width="24%">
<col width="75%">
</colgroup>
<thead><tr class="header">
<th align="center">T1w</th>
<th align="center">T2w</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_1/T1.gif" alt="T1" class="figure"></td>
<td align="center"><img src="../fig/episode_1/T2.gif" alt="T2" class="figure"></td>
</tr></tbody>
</table>
</div>
<div class="section level3">
<h3 id="applications-per-modality">Applications per modality<a class="anchor" aria-label="anchor" href="#applications-per-modality"></a>
</h3>
<table class="table">
<colgroup>
<col width="14%">
<col width="45%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th align="center">Modality</th>
<th align="center">Contrast Characteristics</th>
<th align="center">Use Cases</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">T1w</td>
<td align="center">Cerebrospinal fluid is dark</td>
<td align="center">Quantifying anatomy <em>e.g. measure structural
volumes</em>
</td>
</tr>
<tr class="even">
<td align="center">T2w</td>
<td align="center">CSF is light, but white matter is darker than with
T1</td>
<td align="center">Identify pathologies related to lesions and
tumors</td>
</tr>
<tr class="odd">
<td align="center">PD</td>
<td align="center">CSF is bright. Gray matter is brighter than white
matter</td>
<td align="center">Identify demyelination</td>
</tr>
<tr class="even">
<td align="center">FLAIR</td>
<td align="center">Similar to T2 with the CSF signal suppressed</td>
<td align="center">Identify demyelination</td>
</tr>
</tbody>
</table>
</div>
</section><section><h2 class="section-heading" id="image-acquisition-process-and-parameters">Image acquisition process and parameters<a class="anchor" aria-label="anchor" href="#image-acquisition-process-and-parameters"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_1/Pulse_seq.png" alt="Drawing" align="middle" width="1000px" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="what-do-we-want">What do we want?<a class="anchor" aria-label="anchor" href="#what-do-we-want"></a>
</h2>
<hr class="half-width">
<ul>
<li>High image contrast</li>
<li>High spatial resolution</li>
<li>Low scan time!</li>
</ul></section><section><h2 class="section-heading" id="what-can-we-control">What can we control?<a class="anchor" aria-label="anchor" href="#what-can-we-control"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="magnetic-strengths-1-5t-vs-3t-vs-7t">Magnetic strengths 1.5T vs 3T vs 7T<a class="anchor" aria-label="anchor" href="#magnetic-strengths-1-5t-vs-3t-vs-7t"></a>
</h3>
<ul>
<li>Higher magnetic strength –&gt; better spatial resolution, better SNR
(S ∝ B0^2); but more susceptible to certain artifacts.</li>
</ul>
</div>
<div class="section level3">
<h3 id="mr-sequences-i-e--timings-of-excitation-pulse-gradients-and-echo-acquisition">MR sequences (i.e. timings of “excitation pulse”, “gradients”, and
“echo acquisition” )<a class="anchor" aria-label="anchor" href="#mr-sequences-i-e--timings-of-excitation-pulse-gradients-and-echo-acquisition"></a>
</h3>
<ul>
<li>Spin echo: Slower but better contrast to noise ratio (CNR)</li>
<li>Gradient echo: Quicker but more susceptible to noise</li>
</ul>
<p>e.g. MPRAGE: Magnetization Prepared - RApid Gradient Echo (Commonly
used in neuroimaging)</p>
<table class="table">
<colgroup>
<col width="24%">
<col width="75%">
</colgroup>
<thead><tr class="header">
<th align="center">MP-RAGE</th>
<th align="center">MP2-RAGE</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_1/mprage1.jpg" alt="mprage" class="figure"></td>
<td align="center"><img src="../fig/episode_1/mp2rage.png" alt="Drawing" align="middle" width="425px" class="figure"></td>
</tr></tbody>
</table>
</div>
<div class="section level3">
<h3 id="spatial-encoding-of-the-signal">Spatial encoding of the signal<a class="anchor" aria-label="anchor" href="#spatial-encoding-of-the-signal"></a>
</h3>
<ul>
<li>Spatial frequencies (k-space)</li>
<li>Field of View –&gt; susceptibility to image artifacts
(e.g. Aliasing)</li>
</ul>
<figure><img src="../fig/episode_1/kspace.jpg" alt="kspace" class="figure mx-auto d-block"></figure><p><em>MPRAGE and k-space images Courtesy of Allen D. Elster,
MRIquestions.com</em></p>
</div>
</section><section><h2 class="section-heading" id="interacting-with-images-see-this-notebook-for-detailed-example-">Interacting with images (see <a href="../code/1_sMRI_modalities.ipynb">this notebook</a> for detailed
example.)<a class="anchor" aria-label="anchor" href="#interacting-with-images-see-this-notebook-for-detailed-example-"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> nilearn</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>local_data_dir <span class="op">=</span> <span class="st">'../local_data/1_sMRI_modalities/'</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>T1_filename <span class="op">=</span> local_data_dir <span class="op">+</span> <span class="st">'craving_sub-SAXSISO01b_T1w.nii.gz'</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>T2_filename <span class="op">=</span> local_data_dir <span class="op">+</span><span class="st">'craving_sub-SAXSISO01b_T2w.nii.gz'</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>T1_img <span class="op">=</span> nib.load(T1_filename)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>T2_img <span class="op">=</span> nib.load(T2_filename)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># grab data array</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>T1_data <span class="op">=</span> T1_img.get_fdata()</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>T2_data <span class="op">=</span> T2_img.get_fdata()</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>plotting.plot_anat(T1_filename, title<span class="op">=</span><span class="st">"T1"</span>, vmax<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>plotting.plot_anat(T2_filename, title<span class="op">=</span><span class="st">"T2"</span>, vmax<span class="op">=</span><span class="dv">300</span>)</span></code></pre>
</div>
<table class="table">
<colgroup>
<col width="24%">
<col width="75%">
</colgroup>
<thead><tr class="header">
<th align="center">T1w</th>
<th align="center">T2w</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_1/nilearn_T1.png" alt="nilearn_T1" class="figure"></td>
<td align="center"><img src="../fig/episode_1/nilearn_T2.png" alt="nilearn_T2" class="figure"></td>
</tr></tbody>
</table>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Different acquisition techniques will offer better quantification of
specific brain tissues</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-02-Image_Cleanup"><p>Content from <a href="02-Image_Cleanup.html">sMRI Clean-up</a></p>
<hr>
<p>Last updated on 2025-02-26 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/02-Image_Cleanup.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 45 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the sources of noise and artifacts in MR images?</li>
<li>How do we extract/mask the brain?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Visualize bias fields and motion artifacts</li>
<li>Generate brain masks</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_2/Course_flow_2.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="why-do-we-need-image-clean-ups">Why do we need image clean-ups?<a class="anchor" aria-label="anchor" href="#why-do-we-need-image-clean-ups"></a>
</h2>
<hr class="half-width">
<p>Correcting or cleaning-up certain artifacts from the raw
(i.e. acquired) MR scans is crucial for the successful processing of
subsequent image normalization tasks as well as the downstream
statistical analyses. Some version (i.e. custom algorithm) of these two
tasks is implemented in all commonly deployed processing pipelines such
as FreeSurfer, FSL etc.</p>
<p>In this episode we will look at two common image clean-up tasks 1)
Intensity normalization 2) Brain extraction.</p>
<div class="section level3">
<h3 id="intensity-normalization-a-k-a-bias-field-correction-a-k-a--intensity-inhomogeneity-correction">Intensity normalization (a.k.a bias field correction; a.k.a.
intensity inhomogeneity correction)<a class="anchor" aria-label="anchor" href="#intensity-normalization-a-k-a-bias-field-correction-a-k-a--intensity-inhomogeneity-correction"></a>
</h3>
<ul>
<li><p>The bias field is a low-frequency spatially varying MRI artifact
resulting from spatial inhomogeneity of the magnetic field, variations
in the sensitivity of the reception coil, and the interaction between
the magnetic field and the human body.</p></li>
<li><p>It causes a smooth signal intensity variation within tissue of
the same physical properties.</p></li>
<li><p>The bias field is dependent on the strength of the magnetic
field. If it is not corrected for 1.5T or higher MR scanners, it can
considerably affect downstream analyses. Stronger magnets will induce
higher bias.</p></li>
<li>
<p>Commonly used tools</p>
<ul>
<li>
<a href="https://pubmed.ncbi.nlm.nih.gov/20378467/" class="external-link">ANTs N4 bias
correction</a> (See figure below)</li>
<li>
<a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST" class="external-link">FSL FAST</a>
(<em>Note:FSL FAST is a multi-purpose segmentation tool that includes
the bias field correction.</em>)</li>
</ul>
</li>
</ul>
<div id="bias-field-correction-quiz" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="bias-field-correction-quiz" class="callout-inner">
<h3 class="callout-title">Bias field correction quiz</h3>
<div class="callout-content">
<p>What is the difference between bias field and image noise?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Bias field is modeled as multiplicative factor, whereas noise is
typically assumed as additive and spatially independent (Gaussian)
factor.</p>
<p>i.e. v(x) = u(x)f(x) + n(x), where v is the given image, u is the
uncorrupted image, f is the bias field, and n is the noise.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="ants-n4-correction">ANTs N4 correction<a class="anchor" aria-label="anchor" href="#ants-n4-correction"></a>
</h3>
<ol style="list-style-type: lower-alpha">
<li>Acquired T1w image (b) Estimated the bias field which can then be
used to “correct” the image. (c) Bias field viewed as a surface to show
the low frequency modulation. <img src="../fig/episode_2/N4_bias.jpeg" alt="N4_bias" class="figure">
</li>
</ol>
<div class="section level4">
<h4 id="side-note-ants-is-a-software-comprising-several-tools-and-image-processing-algorithms--ants-can-be-run-independently-or-we-can-import-ants-scripts-in-python-using-nipype-library-">Side-note: <a href="https://stnava.github.io/ANTs/" class="external-link">ANTs</a> is a
software comprising several tools and image processing algorithms. ANTs
can be run independently or we can import ANTs scripts in python using
<a href="https://nipype.readthedocs.io/en/latest/" class="external-link">nipype</a>
library.<a class="anchor" aria-label="anchor" href="#side-note-ants-is-a-software-comprising-several-tools-and-image-processing-algorithms--ants-can-be-run-independently-or-we-can-import-ants-scripts-in-python-using-nipype-library-"></a>
</h4>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> nipype.interfaces.ants <span class="im">import</span> N4BiasFieldCorrection</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>n4 <span class="op">=</span> N4BiasFieldCorrection()</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>n4.inputs.dimension <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>n4.inputs.input_image <span class="op">=</span> <span class="st">'structural.nii'</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>n4.inputs.bspline_fitting_distance <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>n4.inputs.shrink_factor <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>n4.inputs.n_iterations <span class="op">=</span> [<span class="dv">50</span>,<span class="dv">50</span>,<span class="dv">30</span>,<span class="dv">20</span>]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>n4.cmdline</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="st">'N4BiasFieldCorrection --bspline-fitting [ 300 ] -d 3 --input-image structural.nii --convergence [ 50x50x30x20 ] --output structural_corrected.nii --shrink-factor 3'</span></span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="impact-of-correction-source-despotović-et-al-">Impact of correction (<em>source: <a href="https://www.hindawi.com/journals/cmmm/2015/450341/" class="external-link">Despotović et
al.</a></em>)<a class="anchor" aria-label="anchor" href="#impact-of-correction-source-despotovi%C4%87-et-al-"></a>
</h3>
<p>The top figure panel shows original and bias field corrected MR image
slices. The middle figure panel shows the difference in the intensty
histograms for the two image slices. And the bottom figure panel shows
the impact of bias correction on a subsequent image segmentation
task.</p>
<figure><img src="../fig/episode_2/Despotovic_bias_correction.png" alt="bias_correction" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="visualizing-before-and-after">Visualizing “before” and “after”<a class="anchor" aria-label="anchor" href="#visualizing-before-and-after"></a>
</h3>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>T1_orig <span class="op">=</span> subject_dir <span class="op">+</span> <span class="st">'orig.mgz'</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>T1_corrected <span class="op">=</span> subject_dir <span class="op">+</span> <span class="st">'nu.mgz'</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>T1_img_orig <span class="op">=</span> nib.load(T1_orig)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>T1_img_corrected <span class="op">=</span> nib.load(T1_corrected)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>cut_coords <span class="op">=</span> (<span class="op">-</span><span class="dv">85</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">5</span>)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>plotting.plot_anat(T1_orig, title<span class="op">=</span><span class="st">"T1_orig"</span>, cut_coords<span class="op">=</span>cut_coords, vmax<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>plotting.plot_anat(T1_corrected, title<span class="op">=</span><span class="st">"T1_corrected_img"</span>, cut_coords<span class="op">=</span>cut_coords, vmax<span class="op">=</span><span class="dv">255</span>)</span></code></pre>
</div>
<table class="table">
<colgroup>
<col width="47%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th align="center">Before</th>
<th align="center">After</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_2/nilearn_bias_orig.png" alt="nilearn_bias_orig" class="figure"></td>
<td align="center"><img src="../fig/episode_2/nilearn_bias_corr.png" alt="nilearn_bias_corr" class="figure"></td>
</tr></tbody>
</table>
</div>
<div class="section level3">
<h3 id="brain-extraction-a-k-a-skull-stripping">Brain extraction (a.k.a skull-stripping)<a class="anchor" aria-label="anchor" href="#brain-extraction-a-k-a-skull-stripping"></a>
</h3>
<ul>
<li><p>Image contrasts from nonbrain tissues such as fat, skull, or neck
can cause issues with downstream analyses starting with brain tissue
segmentation.</p></li>
<li><p>The brain extraction generates a mask that identifies brain
voxels comprising grey-matter (GM), white-matter(WM), and Cerebrospinal
fluid (CSF) of the cerebral cortex and subcortical structures, including
the brain stem and cerebellum.</p></li>
<li><p>The scalp, dura matter, fat, skin, muscles, eyes, and bones are
classified as nonbrain voxels.</p></li>
<li>
<p>Commonly used tools</p>
<ul>
<li><a href="https://nipype.readthedocs.io/en/latest/api/generated/nipype.interfaces.ants.html#brainextraction" class="external-link">antsBrainExtraction</a></li>
<li><a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET" class="external-link">FSL brain
extraction tool (BET)</a></li>
</ul>
</li>
<li><p>Note 1: At this point we are NOT trying to extract the brain
sulci and gyri (i.e. cortical folds). We are just creating a simple
brain mask for computational purposes, which need not capture the
precise brain anatomy. Thus you may see some marrow and membrain
included in the extracted brain.</p></li>
<li><p>Note 2: Brainstem and spinal cord are continuous so a rather
arbitrarily cut-off point is selected.</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="example-brain-extractions-pass-fail">Example brain extractions pass / fail<a class="anchor" aria-label="anchor" href="#example-brain-extractions-pass-fail"></a>
</h3>
<table class="table">
<colgroup>
<col width="47%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th align="center">Pass</th>
<th align="center">Fail</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_2/BET_Brain_mask_QC_pass.png" alt="Drawing" align="middle" width="400px" class="figure"></td>
<td align="center"><img src="../fig/episode_2/BET_Brain_mask_QC_fail.png" alt="Drawing" align="middle" width="400px" class="figure"></td>
</tr></tbody>
</table>
<p><em>Source: FSL Introduction to Brain Extraction</em></p>
<div id="brain-extraction-quiz" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="brain-extraction-quiz" class="callout-inner">
<h3 class="callout-title">Brain extraction quiz</h3>
<div class="callout-content">
<p>Can we use this brain-mask as an estimate for brain volume?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>Brain mask at this stage only offers a crude estimate about total
brain volume. It can be used for quality control (e.g. detecting
preprocessing algorithm failures). More accurate estimates of total
brain and intracranial volumes are calculated in subsequent steps, which
are used as covariates or normalizing factors in statistical
analysis.</p>
</div>
</div>
</div>
</div>
<div class="section level4">
<h4 id="side-note-ants-is-a-software-comprising-several-tools-and-image-processing-algorithms--ants-can-be-run-independently-or-we-can-import-ants-scripts-in-python-using-nipype-library--1">Side-note: <a href="https://stnava.github.io/ANTs/" class="external-link">ANTs</a> is a
software comprising several tools and image processing algorithms. ANTs
can be run independently or we can import ANTs scripts in python using
<a href="https://nipype.readthedocs.io/en/latest/" class="external-link">nipype</a>
library.<a class="anchor" aria-label="anchor" href="#side-note-ants-is-a-software-comprising-several-tools-and-image-processing-algorithms--ants-can-be-run-independently-or-we-can-import-ants-scripts-in-python-using-nipype-library--1"></a>
</h4>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> nipype.interfaces.ants.segmentation <span class="im">import</span> BrainExtraction</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>brainextraction <span class="op">=</span> BrainExtraction()</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>brainextraction.inputs.dimension <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>brainextraction.inputs.anatomical_image <span class="op">=</span><span class="st">'T1.nii.gz'</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>brainextraction.inputs.brain_template <span class="op">=</span> <span class="st">'study_template.nii.gz'</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>brainextraction.inputs.brain_probability_mask <span class="op">=</span><span class="st">'ProbabilityMaskOfStudyTemplate.nii.gz'</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>brainextraction.cmdline</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="st">'antsBrainExtraction.sh -a T1.nii.gz -m ProbabilityMaskOfStudyTemplate.nii.gz</span></span>
<span><span class="st">-e study_template.nii.gz -d 3 -s nii.gz -o highres001_'</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="ants-brain-extraction">ANTs Brain Extraction<a class="anchor" aria-label="anchor" href="#ants-brain-extraction"></a>
</h4>
<figure><img src="../fig/episode_2/brainextraction_t1.jpg" alt="ANTs_brain_extract" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="fsl-bet">FSL BET<a class="anchor" aria-label="anchor" href="#fsl-bet"></a>
</h4>
<figure><img src="../fig/episode_2/bet2_eg_small.png" alt="FSL_brain_extract" class="figure mx-auto d-block"></figure>
</div>
</div>
<div class="section level3">
<h3 id="visualizing-before-and-after-see---code2_smri_image_cleanup-ipynb-for-detailed-example-">Visualizing “before” and “after” (see
../code/2_sMRI_image_cleanup.ipynb for detailed example.)<a class="anchor" aria-label="anchor" href="#visualizing-before-and-after-see---code2_smri_image_cleanup-ipynb-for-detailed-example-"></a>
</h3>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> nipype.interfaces.ants.segmentation <span class="im">import</span> BrainExtraction</span></code></pre>
</div>
<p>import nibabel as nib from nilearn import plotting</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>T1_normalized <span class="op">=</span> subject_dir <span class="op">+</span> <span class="st">'T1.mgz'</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>T1_brain_extract <span class="op">=</span> subject_dir <span class="op">+</span> <span class="st">'brainmask.mgz'</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>T1_img_normalized <span class="op">=</span> nib.load(T1_normalized)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>T1_img_brain_extract <span class="op">=</span> nib.load(T1_brain_extract)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>cut_coords <span class="op">=</span> (<span class="op">-</span><span class="dv">85</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">5</span>)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>plotting.plot_anat(T1_img_normalized, title<span class="op">=</span><span class="st">"T1_img_normalized"</span>, cut_coords<span class="op">=</span>cut_coords, vmax<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>plotting.plot_anat(T1_img_brain_extract, title<span class="op">=</span><span class="st">"T1_img_brain_extract"</span>, cut_coords<span class="op">=</span>cut_coords, vmax<span class="op">=</span><span class="dv">255</span>)</span></code></pre>
</div>
<table class="table">
<colgroup>
<col width="47%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th align="center">Before</th>
<th align="center">After</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_2/nilearn_brain_orig.png" alt="nilearn_brain_orig" class="figure"></td>
<td align="center"><img src="../fig/episode_2/nilearn_brain_extract.png" alt="nilearn_brain_extract" class="figure"></td>
</tr></tbody>
</table>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Presence of artifacts can lead to flawed analysis and incorrect
findings</li>
</ul>
</div>
</div>
</div>
</div>
</section></section><section id="aio-03-Image_Spatial_Normalization"><p>Content from <a href="03-Image_Spatial_Normalization.html">sMRI Spatial Normalization</a></p>
<hr>
<p>Last updated on 2024-02-19 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/03-Image_Spatial_Normalization.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 45 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are reference coordinate systems</li>
<li>What are ‘templates’, ‘atlases’?</li>
<li>What is spatial normalization?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand reference spaces and registration process</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_3/Course_flow_3.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="why-do-we-need-spatial-normalization">Why do we need spatial normalization<a class="anchor" aria-label="anchor" href="#why-do-we-need-spatial-normalization"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="compare-and-combine-brain-images-across-modalities-individuals-and-studies">Compare and combine brain images across modalities, individuals, and
studies<a class="anchor" aria-label="anchor" href="#compare-and-combine-brain-images-across-modalities-individuals-and-studies"></a>
</h3>
</div>
</section><section><h2 class="section-heading" id="what-do-we-need-for-spatial-normalization">What do we need for spatial normalization<a class="anchor" aria-label="anchor" href="#what-do-we-need-for-spatial-normalization"></a>
</h2>
<hr class="half-width">
<div class="section level4">
<h4 id="a-reference-frame-a-3d-space-that-assigns-xyz-coordinates-to-anatomical-regions-independent-of-voxel-dimensions-">1. A reference frame: A 3D space that assigns x,y,z coordinates to
anatomical regions (independent of voxel dimensions!).<a class="anchor" aria-label="anchor" href="#a-reference-frame-a-3d-space-that-assigns-xyz-coordinates-to-anatomical-regions-independent-of-voxel-dimensions-"></a>
</h4>
</div>
<div class="section level4">
<h4 id="a-common-template-a-single-or-an-average-image-volume-as-an-alignment-target">2. A common template: a single or an average image volume as an
alignment target<a class="anchor" aria-label="anchor" href="#a-common-template-a-single-or-an-average-image-volume-as-an-alignment-target"></a>
</h4>
</div>
<div class="section level4">
<h4 id="an-image-registration-algorithm">3. An image registration algorithm<a class="anchor" aria-label="anchor" href="#an-image-registration-algorithm"></a>
</h4>
</div>
</section><section><h2 class="section-heading" id="coordinate-systems-and-spaces">1. Coordinate systems and spaces<a class="anchor" aria-label="anchor" href="#coordinate-systems-and-spaces"></a>
</h2>
<hr class="half-width">
<ul>
<li>World coordinates</li>
<li>Anatomical coordinates</li>
<li>Image coordinates</li>
</ul>
<figure><img src="../fig/episode_3/Slicer_Wiki_Coordinate_Sytems.png" alt="slicer_coordinate_systems" class="figure mx-auto d-block"></figure><div class="section level4">
<h4 id="image-source">
<em>Image <a href="https://www.slicer.org/wiki/Coordinate_systems" class="external-link">source</a></em><a class="anchor" aria-label="anchor" href="#image-source"></a>
</h4>
</div>
<div class="section level3">
<h3 id="world-coordinates">World coordinates<a class="anchor" aria-label="anchor" href="#world-coordinates"></a>
</h3>
<p>The world coordinates refer to a Cartesian coordinate system in which
a MRI (or other modality) scanner is positioned.</p>
</div>
<div class="section level3">
<h3 id="anatomical-coordinates">Anatomical coordinates<a class="anchor" aria-label="anchor" href="#anatomical-coordinates"></a>
</h3>
<p>The anatomical space is coordinate system (X,Y,Z) that consists of
three planes to describe the standard anatomical position of a human</p>
<ul>
<li>
<em>Axial</em> plane is parallel to the ground and separates the
head (Superior) from the feet (Inferior)</li>
<li>
<em>Coronal</em> plane is perpendicular to the ground and separates
the front (Anterior) from the back (Posterior)</li>
<li>
<em>Sagittal</em> plane separates the Left from the Right</li>
</ul>
<p>The origin and directions of anatomical coordinate system are defined
by conventions. In neuroimaging the most commonly used definition is the
stereotaxic space.</p>
<div class="section level4">
<h4 id="stereotaxic-space">Stereotaxic space<a class="anchor" aria-label="anchor" href="#stereotaxic-space"></a>
</h4>
<ul>
<li>
<p>A 3-dimensional coordinate reference frame based on anatomical
landmarks - originally used to guide neurosurgical procedures.</p>
<ul>
<li>A/P means anterior/posterior</li>
<li>L/R means left/right</li>
<li>S/I means superior/inferior</li>
<li>Example: RAS
<ul>
<li>First dimension (X) points towards the right hand side of the
head</li>
<li>Second dimension (Y) points towards the Anterior aspect of the
head</li>
<li>Third dimension (Z) points towards the top of the head</li>
<li>Directions are from the subject’s perspective. In the RAS coordinate
system, a point to the subject’s left will have a negative x value.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Talairach space</p>
<ul>
<li>Derived from a single 60-yr old female cadaver brain</li>
</ul>
</li>
<li>
<p>MNI space(s)</p>
<ul>
<li>Similar to the original Talairach space but the Z-coordinate has
approximately +3.5 mm offset relative to the Talairach coordinate.</li>
</ul>
</li>
</ul>
<figure><img src="../fig/episode_3/MNI_space_offset.png" alt="Drawing" align="middle" width="500px" class="figure mx-auto d-block"></figure>
</div>
</div>
<div class="section level3">
<h3 id="image-coordinates">Image coordinates<a class="anchor" aria-label="anchor" href="#image-coordinates"></a>
</h3>
<p>The image coordinate system (i,j,k) describes the acquired image
(voxels) with respect to the anatomy. The MR images are 3D voxel arrays
(i.e. grids) whose origin is assigned at the upper left corner. The i
axis increases to the right, the j axis to the bottom and the k axis
backwards.</p>
<p>The MR image metadata stores the <em>anatomical location</em> of the
image origin and the spacing between two voxels (typically in mm).</p>
<p>For examples:</p>
<ul>
<li>image coordinate: (0,0,0) ~ anatomical location: (100mm, 50mm,
-25mm)</li>
<li>The spacing between voxels along each axis: (1.5mm, 0.5mm,
0.5mm)</li>
</ul>
<figure><img src="../fig/episode_3/Slicer_Wiki_Voxel_Spacing.png" alt="Drawing" align="middle" width="500px" class="figure mx-auto d-block"></figure><div class="section level4">
<h4 id="image-source-1">
<em>Image <a href="https://www.slicer.org/wiki/Coordinate_systems" class="external-link">source</a></em><a class="anchor" aria-label="anchor" href="#image-source-1"></a>
</h4>
<div id="quiz-coordinate-systems" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="quiz-coordinate-systems" class="callout-inner">
<h3 class="callout-title">Quiz: coordinate systems</h3>
<div class="callout-content">
<p>What happens when you downsample a MR image?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Downsampling reduces the number of total voxels in the image.
Consequently the voxel-spacing is increased as more anatomical space is
“sampled” by any given voxel. Note that the new intensity values of the
resampled voxels are determined based on the type of interpolation
used.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="mr-image-templates">2. MR image templates<a class="anchor" aria-label="anchor" href="#mr-image-templates"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>An anatomical template is an average MR volume whose voxels
encode the average probability of different tissue classes (e.g. WM, GM,
and CSF) at particular spatial location. The template creation is an
iterative process comprising normalization, alignment, and averaging of
a set of MR images from several different subjects.</p></li>
<li><p>Structural T1‐weighted templates serve as a <em>common reference
space</em> and allow researchers to combine and compare data from
multiple subjects.</p></li>
<li>
<p>Templates play an important role in a variety of neuroimaging
tasks:</p>
<ul>
<li>Target image for spatial normalization in voxel‐wise analyses</li>
<li>Automated intensity based WM, GM, and CSF tissue‐segmentation of MR
images</li>
<li>Anatomical atlas creation for region of interest analyses</li>
<li>Automated seed selection for connectivity analyses</li>
</ul>
</li>
<li><p>A <em>good</em> template is supposed to be a
<em>representative</em> average of the study cohort. However for
computational reasons (template creation is a computationally intensive
process), and to maintain comparability across studies, image processing
pipelines typically use publicly available templates.</p></li>
<li>
<p>Commonly used templates:</p>
<ul>
<li>
<a href="https://ieeexplore.ieee.org/document/373602" class="external-link">MNI 305</a>
<ul>
<li>an average of 305 T1-weighted MRI scans from young healthy
adults</li>
<li>305 normal MRI brains were linearly coregistered (9-param) to 241
brains that had been coregistered (roughly) to the Talairach atlas.</li>
</ul>
</li>
<li>
<a href="https://journals.lww.com/jcat/Abstract/1998/03000/Enhancement_of_MR_Images_Using_Registration_for.32.aspx" class="external-link">Collin27</a>
<ul>
<li>One individual scanned 27 times and the images linearly registered
to create an average with high SNR and structure definition</li>
<li>Linearly registered to the MNI 305</li>
</ul>
</li>
<li>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1088516/" class="external-link">MNI152
linear a.k.a. ICBM152</a> (International Consortium for Brain Mapping)
<ul>
<li>An average of 152 T1-weighted MRI scans from young adults</li>
<li>Linearly coregistered (9-param) to the MNI 305</li>
<li>Higher resolution and better contrast than the MNI305</li>
<li>Used by SPM</li>
</ul>
</li>
<li>
<a href="https://link.springer.com/chapter/10.1007%2F11866763_8" class="external-link">MNI152
nonlinear</a>
<ul>
<li>Version of MNI152 nonlinearly registered to MNI 305</li>
<li>Updated versions
<ul>
<li>MNI152NLin6Asym: used by FSL</li>
<li>MNI152NLin2009cAsym: used by fMRIprep</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.25327" class="external-link">MIITRA</a>
<ul>
<li>An average of 222 T1-weighted MRI scans from <em>older
adults</em>
</li>
<li>Nonlinearly registered to MNI/ICBM152 2009 version.</li>
</ul>
</li>
<li>
<a href="https://pubmed.ncbi.nlm.nih.gov/10619420/" class="external-link">fsaverage</a>
<ul>
<li>
<em>Surface template</em> characterized by “vertices and
faces/triangles”</li>
<li>Spherical alignment of 40 participants</li>
<li>163,842 vertices per hemispheres</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="section level3">
<h3 id="t1-templates-mni305-collin27-mni152-linear-mni152-nonlinear">T1 templates (MNI305, Collin27, MNI152 (linear), MNI152
(nonlinear))<a class="anchor" aria-label="anchor" href="#t1-templates-mni305-collin27-mni152-linear-mni152-nonlinear"></a>
</h3>
<figure><img src="../fig/episode_3/MNI_spaces_caption.jpeg" alt="MNI_spaces" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="multimodal-mniicbm152-atlas">Multimodal MNI/ICBM152 atlas<a class="anchor" aria-label="anchor" href="#multimodal-mniicbm152-atlas"></a>
</h3>
<figure><img src="../fig/episode_3/mni_icbm152_sym_09c_small.jpeg" alt="mni_icbm152" class="figure mx-auto d-block"></figure>
</div>
</section><section><h2 class="section-heading" id="image-registration">3. Image registration<a class="anchor" aria-label="anchor" href="#image-registration"></a>
</h2>
<hr class="half-width">
<div class="section level4">
<h4 id="a-process-that-aligns-an-image-from-one-coordinate-space-to-another-">A process that aligns an image from one coordinate space to
another.<a class="anchor" aria-label="anchor" href="#a-process-that-aligns-an-image-from-one-coordinate-space-to-another-"></a>
</h4>
<ul>
<li>
<p>Purpose</p>
<ul>
<li>building templates</li>
<li>native (subject) space to template-space alignment
(normalization)</li>
<li>inter-subject alignment (typically for cohort specific)</li>
<li>intra-subject alignment (co-registration of image modalities or
longitudinal analyses)</li>
</ul>
</li>
<li>
<p>Image similarity metrics</p>
<ul>
<li>correlation ratio (CR)</li>
<li>cross-correlation (CC)</li>
<li>mutual information (MI)</li>
</ul>
</li>
<li>
<p>Transforms</p>
<ul>
<li>Linear: global feature aligment
<ul>
<li>Rigid (6 parameters): rotation, translation</li>
<li>Affine (12 parameters): rotation, translation, scaling, skewing</li>
</ul>
</li>
<li>Nonlinear (a.k.a elastic): local feature aligment via warping
<ul>
<li>Computationally intensive deformation models with large number of
parameters</li>
<li>Employ diffeomorphic models that preserve topology and source-target
symmetry</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><em>Note: Linear registrations are often used as an initialization
step for non-linear registration.</em></p>
<figure><img src="../fig/episode_3/Registration.png" alt="registration_cartoon" class="figure mx-auto d-block"></figure><ul>
<li>Commonly used algorithms</li>
</ul>
<table style="width:100%;" class="table">
<colgroup>
<col width="20%">
<col width="61%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th align="center">Algorithm</th>
<th align="center">Deformation</th>
<th align="center">~ parameters</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">FSL FLIRT</td>
<td align="center">Linear</td>
<td align="center">9</td>
</tr>
<tr class="even">
<td align="center">ANIMAL</td>
<td align="center">Non-linear (Local translation)</td>
<td align="center">69K</td>
</tr>
<tr class="odd">
<td align="center">DARTEL Toolbox</td>
<td align="center">Non-linear (diffeomorphic)</td>
<td align="center">6.4M</td>
</tr>
<tr class="even">
<td align="center">ANTs (SyN)</td>
<td align="center">Non-linear (bi-directional diffeomorphic)</td>
<td align="center">28M</td>
</tr>
</tbody>
</table>
<ul>
<li>Rigid registration example (<em>source: <a href="https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks" class="external-link">SimpleITK</a></em>):
<ul>
<li>The figure below shows the source image being registered to the
target (left) in an iterative process. The optimized loss is shown on
the right.</li>
</ul>
</li>
</ul>
<figure><img src="../fig/episode_3/registration_visualization_itk.gif" alt="rigid_process" class="figure mx-auto d-block"></figure><ul>
<li>Nonlinear deformation example <em>(source: 3D Slicer <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3466397/" class="external-link">publication</a>,
<a href="https://www.slicer.org/wiki/Documentation:Nightly:Registration:RegistrationLibrary:RegLib_C42" class="external-link">wiki</a>)</em>
<ul>
<li>The figure below shows local deformation (i.e. warping) of source
image due to nonlinear registration.</li>
</ul>
</li>
</ul>
<figure><img src="../fig/episode_3/Silcer_DeformOnly.gif" alt="nonlinear_deform_process" class="figure mx-auto d-block"></figure><div id="quiz-image-registration" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="quiz-image-registration" class="callout-inner">
<h3 class="callout-title">Quiz: Image registration</h3>
<div class="callout-content">
<p>What would the information encoded in the non-linear deformation tell
you about the subject?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>The deformation fields encode information regarding local
morphometric brain changes. These can be quantified using “Jacobians” of
the deformation field, and can be used to assess subtle morphometric
differences between groups or timepoints.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="python-snippet-see---code3_smri_spatial_norm-ipynb-for-detailed-example-">Python snippet (see ../code/3_sMRI_spatial_norm.ipynb for detailed
example.)<a class="anchor" aria-label="anchor" href="#python-snippet-see---code3_smri_spatial_norm-ipynb-for-detailed-example-"></a>
</h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nibabel.affines <span class="im">import</span> apply_affine</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>cut_coords <span class="op">=</span> (<span class="op">-</span><span class="dv">40</span>,<span class="dv">10</span>,<span class="dv">0</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">1.053177</span>, <span class="op">-</span><span class="fl">0.061204</span>, <span class="op">-</span><span class="fl">0.060685</span>, <span class="fl">90.310684</span>],</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>             [<span class="fl">0.070210</span>, <span class="fl">1.009246</span>, <span class="fl">0.117766</span>, <span class="op">-</span><span class="fl">9.806847</span>],</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>             [<span class="fl">0.023069</span>, <span class="op">-</span><span class="fl">0.117785</span>, <span class="fl">1.186777</span>, <span class="fl">13.209366</span>],</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>             [<span class="fl">0.</span> ,<span class="fl">0.</span> , <span class="fl">0.</span>, <span class="fl">1.</span>]])</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>cut_coords_affine_transformed <span class="op">=</span> apply_affine(A, cut_coords)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>x,y,z <span class="op">=</span> cut_coords_affine_transformed</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>cut_coords_affine_transformed_str <span class="op">=</span> <span class="st">"(</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(<span class="bu">int</span>(x),<span class="bu">int</span>(y),<span class="bu">int</span>(z))</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Subject space to refernce space mapping:</span><span class="ch">\n</span><span class="st"> </span><span class="sc">{}</span><span class="st"> --&gt; </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(cut_coords,cut_coords_affine_transformed_str))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Subject space to refernce space mapping:
 (-40, 10, 0) --&gt; (47,-2,11)</code></pre>
</div>
<figure><img src="../fig/episode_3/nilearn_registration.png" alt="nilearn_reg" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="subject-space-vs-reference-space-use-cases">Subject space vs reference space: use cases<a class="anchor" aria-label="anchor" href="#subject-space-vs-reference-space-use-cases"></a>
</h3>
<figure><img src="../fig/episode_3/Subject_vs_common_space.png" alt="subject_vs_ref_space" class="figure mx-auto d-block"></figure><div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Reference coordinate spaces and spatial normalization offer a way to
map and compare brain anatomy across modalities, individuals, and
studies</li>
</ul>
</div>
</div>
</div>
</div>
</section></section><section id="aio-04-Image_Quantification"><p>Content from <a href="04-Image_Quantification.html">sMRI Segmentation and Parcellation</a></p>
<hr>
<p>Last updated on 2024-02-19 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/04-Image_Quantification.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 35 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do we segment the brain into tissue classes ?</li>
<li>How do we further divide a tissue class into sub-components ?</li>
<li>How are volumetric and surface data defined ?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand and visualize tissue segmentation</li>
<li>Manipulate atlases to extract regions of interests</li>
<li>Visualize and interact with both volumetric and surface data</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_4/Course_flow_4.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="segmentation-of-brain-tissues">Segmentation of brain tissues<a class="anchor" aria-label="anchor" href="#segmentation-of-brain-tissues"></a>
</h2>
<hr class="half-width">
<p>Brain anatomy is different for every individual. Brain tissues are
typically divided into:</p>
<ul>
<li>
<strong>grey matter (GM)</strong>, containing neuron cell
bodies</li>
<li>
<strong>white matter (WM)</strong>, including neuron connection
fibers wrapped in a special signal-accelerating substance called
myelin</li>
<li>
<strong>cerebro-spinal fluid (CSF)</strong>, a protecting fluid
present mostly around the brain but also within brain cavities called
ventricles</li>
</ul>
<p>Each class can inform on different aspects of the brain. Therefore it
is often useful to segment the brain in these tissue components for
further processing.</p>
<figure><img src="../fig/episode_4/GM_WM_CSF.png" alt="Brain tissue types" class="figure mx-auto d-block"></figure><p>An important aspect to keep in mind is that aging and disease can
cause tissue modifications. Common changes include a reduction in GM, as
in the case of ageing and neurodegenerative diseases such as
Alzheimer’s. A tumor can cause an important localized change of signal
in the area most impacted by the tumor. Another example is visibly
higher WM signal intensities on T2 MRI images, so called WM
hyper-intensities, which can be related to vascular pathology (common in
aging), or to myelin lesions characteristic of the multiple sclerosis
disease.</p>
<p><img src="../fig/episode_4/brain_atrophy_460px.jpg" alt="Brain atrophy due to Alzheimer's or severe multiple sclerosis disease" class="figure"><em>This image is Copyright © My-MS.org and falls under Image License D
defined under the Image License section of the My-MS.org Disclaimer
page.</em></p>
<p>The analysis of preprocessed structural images then often consists
in:</p>
<ol style="list-style-type: decimal">
<li>Identifying tissue classes – including pathological tissue when
appropriate – and their sub-components: this is done by segmenting the
MRI images, and the topic of the current episode</li>
<li>Quantifying morphological differences: this is typically done by
measuring morphological properties such as GM volume or thickness in the
whole brain or within specific regions, and this is the topic of episode
6</li>
</ol>
<p>Can we measure brain changes in healthy young adults as well ? This
is what we will ultimately try to find out at the end of our lesson
!</p>
<p>In this episode we will more precisely look at:</p>
<ul>
<li>how to segment images into tissue classes, and also also sub-regions
for the case of GM</li>
<li>how to visualize segmentation results both for volumetric and
surface data</li>
</ul>
<div id="which-software-to-use-for-segmentation-and-parcellation" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="which-software-to-use-for-segmentation-and-parcellation" class="callout-inner">
<h3 class="callout-title">Which software to use for segmentation and parcellation ?</h3>
<div class="callout-content">
<p>Common software to segment volumetric data include <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki" class="external-link">FSL</a>, <a href="https://www.fil.ion.ucl.ac.uk/spm" class="external-link">SPM</a> and <a href="https://stnava.github.io/ANTs" class="external-link">ANTS</a>. One of the most used
software to segment surface data (in addition of volumetric data) is <a href="https://surfer.nmr.mgh.harvard.edu" class="external-link">Freesurfer</a>. In this
episode, we will use the outputs generated by <a href="https://github.com/nipreps/smriprep" class="external-link">smriprep</a>/<a href="https://github.com/nipreps/fmriprep" class="external-link">fmriprep</a>, which are
workflows relying on all these software to generate a large variety of
segmentation outputs.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="tissue-segmentation-and-visualization-in-practice">Tissue segmentation and visualization in practice<a class="anchor" aria-label="anchor" href="#tissue-segmentation-and-visualization-in-practice"></a>
</h2>
<hr class="half-width">
<p>The tissues can be differentiated according to the MRI signal
intensity, however as seen in episode 2, the main magnetic field can
introduce bias and create signal inhomogeneities. It is therefore
important to implement bias field correction before carrying out
segmentation according to tissue intensities.</p>
<p>Usually the T1 MRI modality is used for segmentation as it offers the
best contrast between GM, WM and CSF. However combining multiple
modalities (such as T2, PD and FLAIR) can help improving the
segmentation, especially in the presence of lesions.</p>
<p>Tissue segmentation is presented first for normal controls. Then
examples of changes that can happen in disease are shown for patients
having Alzheimer’s or the multiple sclerosis disease.</p>
<div class="section level3">
<h3 id="in-normal-controls">In normal controls<a class="anchor" aria-label="anchor" href="#in-normal-controls"></a>
</h3>
<p>In normal controls, the number of tissue classes is usually fixed
(there are not additional classes of pathological tissue). In practice,
a distribution of the intensity of the different tissue types can be
obtained by loading T1 volumes with <code>nibabel</code> then plotting a
slice with <code>matplotlib</code> and displaying an histogram with
<code>seaborn</code> (a plotting library built on top of
<code>matplotlib</code>). Assuming we already loaded a T1 brain volume
<code>t1_brain_data</code>, visualizing the T1 data and the associated
intensity histogram is obtained with:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Plot first figure</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>plt.imshow(t1_data[:, :, <span class="dv">110</span>], vmax<span class="op">=</span><span class="dv">300000</span>, origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>plt.title(<span class="st">'T1 data before skull-stripping'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Plot second figure</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>plt.imshow(t1_brain_data[:, :, <span class="dv">110</span>], vmax<span class="op">=</span><span class="dv">300000</span>, origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>plt.title(<span class="st">'T1 data after skull-stripping'</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_4/brain_axial_slice.png" alt="Axial slice of the T1 data (after skull-stripping)" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Compute the optimal bin size according to the data</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>bins <span class="op">=</span> np.histogram_bin_edges(t1_brain_data[t1_brain_data <span class="op">!=</span> <span class="dv">0</span>], bins<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Plot the histogram</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>sns.histplot(t1_brain_data[t1_brain_data <span class="op">!=</span> <span class="dv">0</span>], bins<span class="op">=</span>bins)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>, <span class="dv">300000</span>])</span></code></pre>
</div>
<figure><img src="../fig/episode_4/intensity_distribution_all_tissues_together.png" alt="Histogram of the T1 volume data, all tissues together" class="figure mx-auto d-block"></figure><p>We can see here three main components corresponding to GM, WM and
CSF.</p>
<div id="jupyter-notebook-challenge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>Can you modify the code in the Jupyter notebook to plot the histogram
of the brain before skull-stripping ?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Hint </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Try to switch the variable of one T1 image for another.</p>
</div>
</div>
</div>
</div>
<p>We can visualize the segmentation by loading adding an overlay
representing the different tissue classes after segmentation. For this,
we use the <code>nilearn</code> library to plot the <code>t1_seg</code>
segmentation data from <code>smriprep/fmriprep</code>.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>plotting.plot_roi(roi_img<span class="op">=</span>t1_seg, bg_img<span class="op">=</span>t1, alpha<span class="op">=</span><span class="fl">0.3</span>, cmap<span class="op">=</span><span class="st">"Set1"</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/brain_slices_seg_overlay.png" alt="Tissue classes overlayed on the T1 data" class="figure mx-auto d-block"></figure><p>Now that we have access to each tissue class, we can check the
contribution of each in the intensity histogram.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>labels <span class="op">=</span> np.unique(t1_seg_data[t1_seg_data <span class="op">!=</span> <span class="dv">0</span>]).astype(<span class="st">'int'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>palette <span class="op">=</span> itertools.cycle(sns.color_palette(<span class="st">"Set3"</span>))</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> labels:</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    sns.histplot(t1_brain_data[t1_seg_data <span class="op">==</span> label], bins<span class="op">=</span>bins, color<span class="op">=</span><span class="bu">next</span>(palette), alpha<span class="op">=</span><span class="fl">0.6</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_4/intensity_distribution_per_tissue_class.png" alt="Histogram of the T1 volume data, one distribution per tissue" class="figure mx-auto d-block"></figure><div id="a-simple-matter-of-thresholding" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="a-simple-matter-of-thresholding" class="callout-inner">
<h3 class="callout-title">A simple matter of thresholding ?</h3>
<div class="callout-content">
<p>From the previous histogram, does the intensity itself seem enough to
differentiate between different tissue classes ?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>From the shape of the histogram we can see there is some overlap
between the tissue distributions. Segmentation on intensity alone is
most often not enough, and additional information is required, such as
the use of a template with a-priori tissue probability maps (probability
of presence of a given tissue at a given location).</p>
</div>
</div>
</div>
</div>
<div class="section level4">
<h4 id="a-question-of-probability">A question of probability<a class="anchor" aria-label="anchor" href="#a-question-of-probability"></a>
</h4>
<p>In the previous segmentation volume, each voxel has a single integer
value (1, 2 or 3) according to which tissue class it belongs. In
practice however the primary output of segmentation tools are
probability maps: one probability map per tissue class. In this
probability map, each voxel has a value between 0 and 1 to indicate the
probability to belong to that tissue class.</p>
<p>Below is an example of visualization of a GM probability map
<code>GM_probmap</code>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>plotting.plot_roi(roi_img<span class="op">=</span>GM_probmap, bg_img<span class="op">=</span>t1, alpha<span class="op">=</span><span class="fl">0.3</span>, cmap<span class="op">=</span><span class="st">"jet"</span>, vmin<span class="op">=</span><span class="fl">0.5</span>, vmax<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/GM_probmap.png" alt="GM probability map" class="figure mx-auto d-block"></figure><p>The segmentation into GM and WM voxels allows to identify surfaces
surrounding these tissues. The images below show:</p>
<ul>
<li>on the left: the delineation of GM (in pink) and WM (in blue) before
discarding deep GM structures such as the basal ganglia</li>
<li>on the right: the delineation of the outer GM layer called the pial
surface (in red), and the underlying white matter surface (in blue)
after discarding deep GM</li>
</ul>
<figure><img src="../fig/episode_4/GM_WM_surfaces_delineation.png" alt="Delineation of GM and WM" class="figure mx-auto d-block"></figure><p>We can now have a closer look at surface data !</p>
</div>
<div class="section level4">
<h4 id="surface-data">Surface data<a class="anchor" aria-label="anchor" href="#surface-data"></a>
</h4>
<p>Some software such as Freesurfer specialize in surface data.
Contrarily to volumetric data which are collections of voxels, surface
data are collections of vertices and faces of a mesh.</p>
<figure><img src="../fig/episode_4/mesh.png" alt="Delineation of GM and WM" class="figure mx-auto d-block"></figure><p>The most commonly use surfaces are the pial GM and the underlying WM.
Let’s visualize the pial GM using <code>nilearn</code> on the Freesurfer
<code>pial_surf_file</code> output by <code>smriprep/fmriprep</code> and
loaded in the notebook.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># The pial surface is the most external surface of the GM</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>pial_surf <span class="op">=</span> nib.load(pial_surf_file)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>pial_verts, pial_faces <span class="op">=</span> pial_surf.agg_data((<span class="st">'pointset'</span>, <span class="st">'triangle'</span>))</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>plotting.plot_surf((pial_verts, pial_faces))</span></code></pre>
</div>
<figure><img src="../fig/episode_4/mesh_pial_NC.png" alt="Pial mesh from surface segmentation" class="figure mx-auto d-block"></figure><div id="jupyter-notebook-challenge-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge-1" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>Can you modify the code in the Jupyter notebook to plot the white
matter surface ?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Hint </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>Try to explore the BIDSLayout output to find the right surface
file.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="in-disease-such-as-alzheimers-and-multiple-sclerosis">In disease such as Alzheimer’s and multiple sclerosis<a class="anchor" aria-label="anchor" href="#in-disease-such-as-alzheimers-and-multiple-sclerosis"></a>
</h3>
<p>The brain GM volume tends to shrink with age, with the GM loss
typically replaced with CSF. This process is called atrophy. In
Alzheimer’s disease and other neuro-degenerative disease, atrophy is
amplified (the “degeneration” is the loss of GM). Therefore special care
is required when processing data of patients whose disease can cause
changes in the brain morphology.</p>
<p>Below is a T1 image of an Alzheimer’s disease patient. An enlargement
of the CSF-containing cavities, the ventricles, can be seen.</p>
<figure><img src="../fig/episode_4/NC_vs_AD.png" alt="WM mesh from surface segmentation" class="figure mx-auto d-block"></figure><p>Below is a T1 and FLAIR image of an MS patient. The lesion-enhancing
FLAIR modality clearly show lesions. These lesions can sometimes be seen
on the T1 image. In this case they appear as dark spots called “black
holes”.</p>
<figure><img src="../fig/episode_4/MS_T1_FLAIR_width640.png" alt="WM mesh from surface segmentation" class="figure mx-auto d-block"></figure><div id="segmentation-problems-in-disease" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="segmentation-problems-in-disease" class="callout-inner">
<h3 class="callout-title">Segmentation problems in disease</h3>
<div class="callout-content">
<p>What problems do you expect in the tissue segmentation of multiple
sclerosis images ?</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p>An algorithm expecting three tissues types may misclassify lesions as
GM on T1 images. Filling lesions with intensity corresponding to WM is a
solution sometimes used to avoid these issues (e.g. with Freesurfer).
Some software such as ANTs directly accepts a binary lesion mask as an
input to deal with this kind of data.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="segmenting-tissue-classes-into-sub-components-atlasing-parcellation">Segmenting tissue classes into sub-components: atlasing,
parcellation<a class="anchor" aria-label="anchor" href="#segmenting-tissue-classes-into-sub-components-atlasing-parcellation"></a>
</h2>
<hr class="half-width">
<p>A natural step after identifying tissue classes, is sub-dividing the
tissue(s) of interest into sub-components. GM is commonly split into
non-overlapping regions of interests (ROIs). This splitting process is
called “parcellation” and allows to be more specific about the brain
areas studied. Parcellation can be purely data-driven,
anatomically-driven, or both.</p>
<p>In this lesson we focus on GM. WM parcellation is also common but it
requires dedicated MRI sequences and analysis techniques, e.g. by
identifying group of WM tracts called bundles with tractography (please
refer to the lesson on diffusion MRI if you would like to know more
about WM parcellation).</p>
<p>The usefulness of an atlas comes from the fact that each subject
brain can be registered to the template on which that atlas is defined.
A correct registration to the template is therefore essential for a
correct labelling of the brain voxels / vertices. The template the
images are registered to should also be the template on which the atlas
has been defined (or highly similar).</p>
<div id="atlas-vs-parcellation" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="atlas-vs-parcellation" class="callout-inner">
<h3 class="callout-title">Atlas vs Parcellation</h3>
<div class="callout-content">
<p>A parcellation can be defined as the splitting of an object into
non-overlapping components. Since an atlas divide the brain into
regions, atlasing can be considered a kind of parcellation.
Reciprocally, any kind of brain parcellation can be considered an
“atlas”.</p>
<p>A difference is that an atlas is often expected to be defined on an
entire brain, while a parcellation can be limited to a specific region
(e.g. thalamus parcellation). A parcellation can also be applied for
example to the cortical GM (the outer layer of the brain) or the
subcortical GM for deep GM (GM structures below the cortex).</p>
<p>Note that Freesurfer call cortical parcellation “parcellation”
(denoting <code>parc</code> the associated files) and subcortical
parcellation “segmentation” (denoting <code>seg</code> the associated
files).</p>
<p>The picture can be muddled when considering probabilistic atlases. In
this case each atlas region is associated to a probabilistic map. Just
like tissue probability maps, each voxel (or vertex) has a given
probability to belong to the region considered.</p>
<div id="probability-atlas-threshold" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="probability-atlas-threshold" class="callout-inner">
<h3 class="callout-title">Probability atlas threshold</h3>
<div class="callout-content">
<p>Given a probabilistic atlas, is there a single probability threshold
which would guaranteed each brain volume voxel (or surface vertices) to
have a unique label ? If yes, which threshold would you choose, and if
not how would you proceed ?</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" data-bs-parent="#accordionSolution5" aria-labelledby="headingSolution5">
<div class="accordion-body">
<p>In virtually all cases no single probability threshold will result in
each voxel (or vertex) belonging to a unique ROI. A high threshold will
result in voxels not having a label, while a low threshold will cause
voxels to belong to overlapping probability maps. A “true” parcellation
could be obtained by associating to each voxel (or vertex) the label
with the maximum probability.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="visualizing-and-extracting-rois-of-a-non-probabilistic-volumetric-atlas">Visualizing and extracting ROIs of a non probabilistic volumetric
atlas<a class="anchor" aria-label="anchor" href="#visualizing-and-extracting-rois-of-a-non-probabilistic-volumetric-atlas"></a>
</h3>
<p>An example of a volumetric atlas motivated by neuroanatomy is the
Automated Anatomical Labeling (AAL) atlas. Each ROI has an anatomically
meaningful text label. The atlas is aligned with the MNI MRI
single-subject brain. The atlas is represented as a 3D volume in which
each voxel has an integer index which corresponds to an ROI label,
e.g. <code>2401</code> for the
<code>left hemisphere supplementary motor area</code>.</p>
<p><code>Nilearn</code> offers a collection of atlases in its
<code>datasets</code> module. The AAL atlas, text labels and integer
indices can all be obtained through this module.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> nilearn.datasets <span class="im">import</span> fetch_atlas_aal</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>AAL_dataset <span class="op">=</span> fetch_atlas_aal()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>AAL_maps <span class="op">=</span> AAL_dataset.maps</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>AAL_labels <span class="op">=</span> AAL_dataset[<span class="st">'labels'</span>]</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>AAL_labels_ix <span class="op">=</span> AAL_dataset[<span class="st">'indices'</span>]</span></code></pre>
</div>
<p>We can check the atlas dimension by loading it with
<code>nibabel</code></p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>AAL_img <span class="op">=</span> nib.load(AAL_maps)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>AAL_img.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(91, 109, 91)</code></pre>
</div>
<div class="section level4">
<h4 id="plotting-the-atlas">Plotting the atlas<a class="anchor" aria-label="anchor" href="#plotting-the-atlas"></a>
</h4>
<p>To plot the atlas we can use as background either the template on
which it was defined (or one highly similar), or a subject volume
aligned with that template. In our case we use the <code>t1_mni</code>
volume of our subject and use the <code>plot_roi</code> function of the
<code>nilearn</code> <code>plotting</code> module to add the atlas as an
overlay:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>plotting.plot_roi(roi_img<span class="op">=</span>AAL_maps, bg_img<span class="op">=</span>t1_mni, alpha<span class="op">=</span><span class="fl">0.4</span>, title<span class="op">=</span><span class="st">"AAL atlas"</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/AAL_atlas.png" alt="AAL atlas" class="figure mx-auto d-block"></figure><p>We can extract a specific ROI in two steps:</p>
<ol style="list-style-type: decimal">
<li>Identify the integer index corresponding to the ROI</li>
<li>Get all the voxels corresponding to that index</li>
</ol>
</div>
<div class="section level4">
<h4 id="identifying-an-roi-integer-index">Identifying an ROI integer index<a class="anchor" aria-label="anchor" href="#identifying-an-roi-integer-index"></a>
</h4>
<p>Sometimes the integer index directly correspond to the label list
index, e.g. if “visual cortex” is in position 3 in AAL_dataset[‘labels’]
then the corresponding integer index in the image is 3. For the AAL
atlas, the ROI indices are not in the order of the text labels so
<code>nilearn</code> provide a list of ROI indices. Since the list of
labels match the list of indices we proceed in two steps:</p>
<ol style="list-style-type: decimal">
<li>Find the position of the ROI in the list of AAL_labels</li>
<li>Use the same position in the list of indices</li>
</ol>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>roi_label <span class="op">=</span> <span class="st">"Supp_Motor_Area_L"</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>roi_label_pos <span class="op">=</span> AAL_labels.index(roi_label)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>roi_ix <span class="op">=</span> <span class="bu">int</span>(AAL_labels_ix[roi_label_pos])</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="bu">print</span>(roi_ix)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">2401</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="getting-all-voxels-corresponding-to-that-index">Getting all voxels corresponding to that index<a class="anchor" aria-label="anchor" href="#getting-all-voxels-corresponding-to-that-index"></a>
</h4>
<p>To create a binary ROI image from the ROI index, we:</p>
<ol style="list-style-type: decimal">
<li>Create a boolean array with <code>True</code> if the voxel label is
equal to our ROI index, and <code>False</code> if not</li>
<li>Convert the boolean array to integer</li>
</ol>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>roi_mask_arr_bool <span class="op">=</span> (AAL_img.get_fdata() <span class="op">==</span> roi_ix)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>roi_mask_arr <span class="op">=</span> roi_mask_arr_bool.astype(<span class="bu">int</span>)</span></code></pre>
</div>
<p>To create a <code>nibabel</code> image object, we then need to attach
the original image affine transform</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>roi_mask <span class="op">=</span> nib.Nifti1Image(roi_mask_arr, affine<span class="op">=</span>AAL_img.affine)</span></code></pre>
</div>
<p>we can now plot the ROI using the <code>plot_roi</code> function of
<code>nilearn</code></p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>plotting.plot_roi(roi_img<span class="op">=</span>roi_mask, bg_img<span class="op">=</span>t1_mni, alpha<span class="op">=</span><span class="fl">0.4</span>, title<span class="op">=</span>roi_label)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/AAL_roi.png" alt="ROI from the AAL atlas" class="figure mx-auto d-block"></figure>
</div>
</div>
<div class="section level3">
<h3 id="visualizing-and-extracting-rois-of-a-surface-atlas">Visualizing and extracting ROIs of a surface atlas<a class="anchor" aria-label="anchor" href="#visualizing-and-extracting-rois-of-a-surface-atlas"></a>
</h3>
<p>For the previous atlas, the unit elements to receive a label were
voxels. When considering the surface of the cortex, unit elements are
the vertices of the surface mesh. Each such vertex can receive a label,
and the result is a surface parcellation.</p>
<p>Freesurfer relies on two surface atlases: the Desikan-Killiany Atlas
with 68 ROIs and the Destrieux Atlas with 148 ROIs. The Destrieux atlas
is part of the nilearn datasets and we will focus on this atlas in the
lesson.</p>
<p>Surface datasets are split in left and right hemisphere. Let’s aim at
plotting the left hemisphere. As we will see also how to plot a specific
ROI, we will also extract the atlas labels.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">from</span> nilearn.datasets <span class="im">import</span> fetch_atlas_surf_destrieux</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>parcellation_L <span class="op">=</span> destrieux[<span class="st">'map_left'</span>]</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>destrieux_labels <span class="op">=</span> destrieux[<span class="st">'labels'</span>]</span></code></pre>
</div>
<div class="section level4">
<h4 id="plotting-the-atlas-1">Plotting the atlas<a class="anchor" aria-label="anchor" href="#plotting-the-atlas-1"></a>
</h4>
<p>For plotting a 3D volume we needed a 3D image template. For a
surface, we need a 3D surface (also called mesh) template. The Destrieux
atlas we collected is defined on the fsaverage5 Freesurfer template, so
we will need it to plot our atlas.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>fsaverage <span class="op">=</span> fetch_surf_fsaverage()</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>mesh <span class="op">=</span> fsaverage[<span class="st">'pial_left'</span>]</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>plotting.plot_surf_roi(mesh, roi_map<span class="op">=</span>parcellation_L,</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>                       hemi<span class="op">=</span><span class="st">'left'</span>, view<span class="op">=</span><span class="st">'lateral'</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/destrieux_atlas_left.png" alt="Left hemisphere of the Destrieux surface atlas" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="extracting-a-specific-roi">Extracting a specific ROI<a class="anchor" aria-label="anchor" href="#extracting-a-specific-roi"></a>
</h4>
<p>To extract a specific ROI, we can proceed as we did for the AAL atlas
but using the Destrieux labels.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>pcc_region <span class="op">=</span> <span class="st">b'G_cingul-Post-dorsal'</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>roi_ix <span class="op">=</span> destrieux_labels.index(pcc_region)</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>roi_mask_arr <span class="op">=</span> (parcellation_L <span class="op">==</span> roi_ix).astype(<span class="bu">int</span>)</span></code></pre>
</div>
<p>To plot that ROI, we can use the <code>plot_surf_roi</code> function
of the <code>nilearn</code> <code>plotting</code> module. We will plot
the medial view since this ROI is located towards the central part of
the brain. We will also use the template as background image since most
vertices do not have a label to be plotted.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>plotting.plot_surf_roi(mesh, roi_map<span class="op">=</span>roi_mask_arr, hemi<span class="op">=</span><span class="st">'left'</span>, view<span class="op">=</span><span class="st">'medial'</span>,</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>                       bg_map<span class="op">=</span>fsaverage[<span class="st">'sulc_left'</span>])<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_4/roi_destrieux.png" alt="ROI of the Destrieux surface atlas" class="figure mx-auto d-block"></figure><div id="jupyter-notebook-challenge-2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge-2" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>Can you modify the code in the Jupyter notebook to extract and
display the right precuneus ?</p>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Hint </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" data-bs-parent="#accordionSolution6" aria-labelledby="headingSolution6">
<div class="accordion-body">
<p>This exercise involves a change of both ROI and hemisphere.</p>
</div>
</div>
</div>
</div>
<p>Because atlases can be overlaid on a subject brain registered to the
atlas template, one can extract measurements specific to that subject
within each atlas ROI. We will see common metrics and how to extract
them in episode 6, and the important role of the WM and GM pial surfaces
for this purpose.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Brain segmentation and parcellation is a key step towards further
analysis</li>
<li>The brain can be represented via different data format (volume,
surface)</li>
<li>Multiple python libraries are particularly useful to manipulate
brain data</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="aio-05-Image_QC"><p>Content from <a href="05-Image_QC.html">sMRI Quality Control</a></p>
<hr>
<p>Last updated on 2025-02-26 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/05-Image_QC.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do we identify image preprocessing failures?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Visualize processing failures</li>
<li>Familiarize with automatic QC tools</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_5/Course_flow_5.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="things-that-can-go-wrong">Things that can go wrong…<a class="anchor" aria-label="anchor" href="#things-that-can-go-wrong"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="acquistion">Acquistion<a class="anchor" aria-label="anchor" href="#acquistion"></a>
</h3>
<div class="section level4">
<h4 id="due-to-mr-physics-e-g--field-of-view-fov-ghosting-aliasing">Due to MR physics (e.g. Field of view (FOV), ghosting,
aliasing)<a class="anchor" aria-label="anchor" href="#due-to-mr-physics-e-g--field-of-view-fov-ghosting-aliasing"></a>
</h4>
<p>Incorrect parameters can truncate and/or duplicate brain anatomy.</p>
<figure><img src="../fig/episode_5/MR_physics_QC.png" alt="Drawing" align="middle" width="500px" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="due-to-participant-e-g--motion-artifacts">Due to participant (e.g. Motion artifacts)<a class="anchor" aria-label="anchor" href="#due-to-participant-e-g--motion-artifacts"></a>
</h4>
<ul>
<li>Participant specific issues such as motion artifcats in Parkinson’s
patients can manifest in the scan (e.g. ringing effect showing ripples
or curved lines).</li>
</ul>
<figure><img src="../fig/episode_5/Motion_QC.png" alt="Drawing" align="middle" width="500px" class="figure mx-auto d-block"></figure>
</div>
</div>
<div class="section level3">
<h3 id="quantification">Quantification<a class="anchor" aria-label="anchor" href="#quantification"></a>
</h3>
<p>Exisiting image processing pipelines (e.g. FreeSurfer, CIVET) will
have a few QC tools and examples that can help with failure detection
and quality control of volumetric segmentations and surface
parcellations.</p>
<figure><img src="../fig/episode_5/Segment_and_surface_QC.png" alt="Drawing" align="middle" width="500px" class="figure mx-auto d-block"></figure><p>Usage of new method will require your own QC protocols. Especially
for highly specific segmentation methods require visual inspection from
a neuroanatomy expert. Even for the qualitiative visual inspection, it
is important create a QC protocol and share it with the results.</p>
<figure><img src="../fig/episode_5/HC_and_CB_MAGeT.png" alt="HC_and_CB_MAGeT" class="figure mx-auto d-block"></figure><p><em>Note: see <a href="https://dx.doi.org/10.1016/j.neuroimage.2014.04.054" class="external-link">Hippocampal</a>
and <a href="https://www.sciencedirect.com/science/article/pii/S1053811914001840?via%3Dihub" class="external-link">cerebellar</a>
for segmentation method details.</em></p>
</div>
</section><section><h2 class="section-heading" id="automatic-qc-tools">Automatic QC tools<a class="anchor" aria-label="anchor" href="#automatic-qc-tools"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="using-reports-from-exisiting-pipelines-httpsfmriprep-orgenstable_staticsample_report-html">Using reports from exisiting pipelines: <a href="https://fmriprep.org/en/stable/_static/sample_report.html" class="external-link">https://fmriprep.org/en/stable/_static/sample_report.html</a>
<a class="anchor" aria-label="anchor" href="#using-reports-from-exisiting-pipelines-httpsfmriprep-orgenstable_staticsample_report-html"></a>
</h3>
<figure><img src="../fig/episode_5/sMRIPrep_QC_report.png" alt="Drawing" align="middle" width="700px" class="figure mx-auto d-block"></figure>
</div>
<div class="section level3">
<h3 id="using-qc-tools">Using QC tools<a class="anchor" aria-label="anchor" href="#using-qc-tools"></a>
</h3>
<div class="section level4">
<h4 id="mriqc-extracts-no-reference-iqms-image-quality-metrics-from-structural-t1w-and-t2w-and-functional-mri-magnetic-resonance-imaging-data--developed-by-the-poldrack-lab-at-stanford-university-for-use-at-the-center-for-reproducible-neuroscience-crn-as-well-as-for-open-source-software-distribution-">
<a href="https://github.com/poldracklab/mriqc" class="external-link">MRIQC</a>: extracts
no-reference IQMs (image quality metrics) from structural (T1w and T2w)
and functional MRI (magnetic resonance imaging) data. <em>(Developed by
the Poldrack Lab at Stanford University for use at the Center for
Reproducible Neuroscience (CRN), as well as for open-source software
distribution.)</em>
<a class="anchor" aria-label="anchor" href="#mriqc-extracts-no-reference-iqms-image-quality-metrics-from-structural-t1w-and-t2w-and-functional-mri-magnetic-resonance-imaging-data--developed-by-the-poldrack-lab-at-stanford-university-for-use-at-the-center-for-reproducible-neuroscience-crn-as-well-as-for-open-source-software-distribution-"></a>
</h4>
<table class="table">
<colgroup>
<col width="34%">
<col width="65%">
</colgroup>
<thead><tr class="header">
<th align="center">Individual report</th>
<th align="center">Group report</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_5/mriqc_individual_report.png" alt="Drawing" align="middle" width="700px" class="figure"></td>
<td align="center"><img src="../fig/episode_5/mriqc_group_report.png" alt="Drawing" align="middle" width="450px" class="figure"></td>
</tr></tbody>
</table>
</div>
<div class="section level4">
<h4 id="visualqc-assistive-tool-to-improve-the-quality-control-workflow-of-neuroimaging-data-author-pradeep-reddy-raamana-">
<a href="https://github.com/raamana/visualqc" class="external-link">VisualQC</a>:
assistive tool to improve the quality control workflow of neuroimaging
data (Author: Pradeep Reddy Raamana).<a class="anchor" aria-label="anchor" href="#visualqc-assistive-tool-to-improve-the-quality-control-workflow-of-neuroimaging-data-author-pradeep-reddy-raamana-"></a>
</h4>
<table class="table">
<colgroup>
<col width="25%">
<col width="47%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="center">T1w acquisition</th>
<th align="center">Alignment</th>
<th align="center">Cortical Parcellation</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="../fig/episode_5/t1_mri_visual_QC.png" alt="t1_mri_visual_QC" class="figure"></td>
<td align="center"><img src="../fig/episode_5/alignment_mismatched_colormix_visualQC.png" alt="alignment_mismatched_colormix_visualQC" class="figure"></td>
<td align="center"><img src="../fig/episode_5/cortical_zoomed_in.png" alt="cortical_zoomed_in" class="figure"></td>
</tr></tbody>
</table>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Image processing failures happen! It is important to perform
systematic quality control to minimize biases</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="aio-06-Statistical_Analysis"><p>Content from <a href="06-Statistical_Analysis.html">sMRI Statistical Analysis</a></p>
<hr>
<p>Last updated on 2024-02-19 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/06-Statistical_Analysis.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 35 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to quantify brain morphology ?</li>
<li>How to assess statistically differences of brain morphology ?</li>
<li>Can we detect brain changes related to age in a cohort of young
adults ?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the main metrics characterizing the brain morphology</li>
<li>Extract and rely on a set of metrics to assess the effect of age on
multiple cortical regions</li>
<li>Understand and implement voxel based morphometry to investigate the
effect of age without predefined regions</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_6/Course_flow_6.png" alt="course_flow" class="figure mx-auto d-block"></figure><p>All the previous episodes presented the required steps to arrive at a
stage where the data is ready for metrics extraction and statistical
analysis. In this episode we will introduce common metrics used to
characterize the brain structure and morphology, and we will investigate
statistical approaches to assess if age related brain changes can be
found in a cohort of young adults.</p>
</section><section><h2 class="section-heading" id="quantifying-tissue-properties">Quantifying tissue properties<a class="anchor" aria-label="anchor" href="#quantifying-tissue-properties"></a>
</h2>
<hr class="half-width">
<p>As seen in previous episodes, brain structural data can be
represented as volumes or surfaces. Each of these representations are
associated to different characteristics. In this episode we will look
at:</p>
<ul>
<li>how to measure GM volume when looking at volumetric data,
i.e. voxels</li>
<li>how to extract cortical thickness measures derived from surface
data, i.e. meshes</li>
</ul>
<div class="section level3">
<h3 id="metric-from-volumetric-data-region-volumes">Metric from volumetric data: region volumes<a class="anchor" aria-label="anchor" href="#metric-from-volumetric-data-region-volumes"></a>
</h3>
<p>A simple metric to quantify brain imaging data is volume. The image
is represented as voxels, however the voxel dimensions can vary from one
MRI sequence to another. Some FLAIR sequences have 1.5 mm isotropic
voxels (i.e. 1.5 mm wide in all directions), while T1 sequences have 1
mm isotropic voxels. Other sequences do not have isotropic voxels (the
voxel dimensions vary depending on direction). As a result the number of
voxels is not useful to compare subjects and a standard unit such that
mm3 or cm3 should be used instead.</p>
<p>We will consider here a volumetric atlas created by
<code>smriprep/fmriprep</code> via <code>Freesurfer</code>. A
particularity is that this atlas is mapped to the subject native space
so that we can measure the volume of each atlas ROI in the space of the
subject. Our aim is to measure the volume of the right caudate nucleus,
in standard unit (mm3). We will first see how to obtain the volume
manually, and then how to simply retrieve it from a file referencing
several region volumes.</p>
<div class="section level4">
<h4 id="measuring-an-roi-volume-manually">Measuring an ROI volume manually<a class="anchor" aria-label="anchor" href="#measuring-an-roi-volume-manually"></a>
</h4>
<p>Consider a subject’s native T1 volume <code>t1</code> and a
parcellation of the subcortical GM provided by Freesurfer in that space,
<code>t1_aseg</code>. We already know from episode 4 how to extract an
ROI. According to the <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT" class="external-link">Freesurfer
Look-up Table</a> the right caudate has index 50.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>roi_ix <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>roi_mask_arr_bool <span class="op">=</span> (t1_aseg_data <span class="op">==</span> roi_ix)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>roi_mask_arr <span class="op">=</span> roi_mask_arr_bool.astype(<span class="bu">int</span>)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>roi_mask <span class="op">=</span> nib.Nifti1Image(roi_mask_arr, affine<span class="op">=</span>t1_aseg.affine)</span></code></pre>
</div>
<p>We can verify our ROI extraction by plotting it over the subject’s T1
data with <code>nilearn</code> <code>plotting</code> function:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>plotting.plot_roi(roi_img<span class="op">=</span>roi_mask, bg_img<span class="op">=</span>t1, alpha<span class="op">=</span><span class="fl">0.4</span>, title<span class="op">=</span><span class="st">'Right Caudate'</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_6/right_caudate_ROI.png" alt="Caudate nucleus from Freesurfer segmentation" class="figure mx-auto d-block"></figure><p>We can get the number of voxels by counting them in the mask.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>caudate_R_n_vox <span class="op">=</span> roi_mask_arr.<span class="bu">sum</span>()</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>caudate_R_n_vox</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">3854</span></span></code></pre>
</div>
<p>An image voxel size can be obtained from the file metadata (i.e. data
annotation) stored in the image header. <code>nibabel</code> provide an
<code>header</code> attribute with a method <code>get_zooms()</code> to
obtain the voxel size.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>voxel_dimensions <span class="op">=</span> t1.header.get_zooms()</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>voxel_dimensions</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(1.0, 1.0, 1.0)</code></pre>
</div>
<p>In our case the volume of the voxel, the product of its dimensions,
is simply 1mm3:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>vox_size <span class="op">=</span> np.array(voxel_dimensions).prod()</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>vox_size</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">1.0</span></span></code></pre>
</div>
<p>The volume in mm3 of the right caudate of our subject is then:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>caudate_R_vol_mm3 <span class="op">=</span> caudate_R_n_vox <span class="op">*</span> vox_size</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>caudate_R_vol_mm3</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">3854.0</span></span></code></pre>
</div>
<p>Note that <code>nibabel</code> offers a utility function to compute
the volume of a mask in mm3 according to the voxel size:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> nibabel.imagestats <span class="im">as</span> imagestats</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>imagestats.mask_volume(roi_mask)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">3854.0</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="extracting-roi-volume-from-software-generated-reports">Extracting ROI volume from software generated reports<a class="anchor" aria-label="anchor" href="#extracting-roi-volume-from-software-generated-reports"></a>
</h4>
<p>It turns out that characteristics of a number of ROIs are output by
Freesurfer and saved in a text file. For example the volume of
subcortical ROIs can be found in the file <code>stats/aseg.stats</code>.
We use the function <code>islice</code> of the Python
<code>itertools</code> module to extract the first lines of the
file:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>n_lines <span class="op">=</span> <span class="dv">110</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(os.path.join(fs_rawstats_dir, <span class="st">"aseg.stats"</span>)) <span class="im">as</span> fs_stats_file:</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>    first_n_lines <span class="op">=</span> <span class="bu">list</span>(islice(fs_stats_file, n_lines))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['# Title Segmentation Statistics \n',
 '# \n',
 '# generating_program mri_segstats\n',
 '# cvs_version $Id: mri_segstats.c,v 1.121 2016/05/31 17:27:11 greve Exp $\n',
 '# cmdline mri_segstats --seg mri/aseg.mgz --sum stats/aseg.stats --pv mri/norm.mgz --empty --brainmask mri/brainmask.mgz --brain-vol-from-seg --excludeid 0 --excl-ctxgmwm --supratent --subcortgray --in mri/norm.mgz --in-intensity-name norm --in-intensity-units MR --etiv --surf-wm-vol --surf-ctx-vol --totalgray --euler --ctab /opt/freesurfer/ASegStatsLUT.txt --subject sub-0001 \n',
...
 '# ColHeaders  Index SegId NVoxels Volume_mm3 StructName normMean normStdDev normMin normMax normRange  \n',
 '  1   4      3820     4245.9  Left-Lateral-Ventricle            30.4424    13.2599     7.0000    83.0000    76.0000 \n',
...
 ' 23  49      7142     6806.7  Right-Thalamus-Proper             83.4105    10.4588    32.0000   104.0000    72.0000 \n',
 ' 24  50      3858     3804.7  Right-Caudate                     73.2118     7.9099    37.0000    96.0000    59.0000 \n',
 ' 25  51      5649     5586.9  Right-Putamen                     79.4707     7.1056    46.0000   103.0000    57.0000 \n',
...</code></pre>
</div>
<p>Surprisingly the volume in mm3 is not the same as we found: 3804.7.
This is because instead of counting each voxel in the GM mask as 100%,
the fraction of estimated GM was taken into account. The estimation of
the so called “partial volume” can be done in several manners. One which
will be useful for us later is to use the GM probability map
<code>GM_probmap</code> as a surrogate of a GM partial volume map. Let’s
see the ROI volume we obtain in this way:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>GM_roi_data <span class="op">=</span> np.where(roi_mask_arr_bool, GM_probmap.get_fdata(), <span class="dv">0</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>GM_roi_data.<span class="bu">sum</span>() <span class="op">*</span> vox_size</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">3354.5343634674136</span></span></code></pre>
</div>
<p>Like with Freesurfer we observe a reduction of GM, albeit
significantly more pronounced.</p>
<div id="jupyter-notebook-challenge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>Taking into account partial volume, can you measure the volume of the
Left Caudate ? And if you feel adventurous of the Left Lateral ventricle
?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Hint
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Use the Freesurfer LUT to identify the correct ROI index. For the
lateral ventricle, make sure you use the appropriate tissue type to
correct for partial volume effect.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="metric-from-surface-data-cortical-thickness">Metric from surface data: cortical thickness<a class="anchor" aria-label="anchor" href="#metric-from-surface-data-cortical-thickness"></a>
</h3>
<p>As seen in the previous section, volumetric ROI metrics can be made
available by dedicated software. This is also the case for surface
metrics which are often more involved than computing the number of
voxels. One of the most used surface metric is cortical thickness: the
distance separating the GM pial surface from the WM surface directly
underneath. We will use the output from Freesurfer to:</p>
<ul>
<li>extract cortical thickness information</li>
<li>plot the associated surface data for one subject</li>
<li>generate and plot summary group measurements</li>
</ul>
<div class="section level4">
<h4 id="extracting-cortical-thickness-information">Extracting cortical thickness information<a class="anchor" aria-label="anchor" href="#extracting-cortical-thickness-information"></a>
</h4>
<p>Freesurfer output a number of files including both volume and surface
metrics. These files are generated by Freesurfer for each subject and
can be found in <code>derivatives/freesurfer/stats</code> when using
<code>smriprep/fmriprep</code>.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>os.listdir(fs_rawstats_dir)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['lh.BA_exvivo.thresh.stats',
 'rh.aparc.a2009s.stats',
 'rh.aparc.pial.stats',
 'rh.aparc.DKTatlas.stats',
 'lh.curv.stats',
 'lh.w-g.pct.stats',
 'wmparc.stats',
 'lh.aparc.stats',
 'rh.BA_exvivo.thresh.stats',
 'rh.BA_exvivo.stats',
 'rh.w-g.pct.stats',
 'lh.aparc.pial.stats',
 'lh.BA_exvivo.stats',
 'rh.curv.stats',
 'aseg.stats',
 'lh.aparc.DKTatlas.stats',
 'lh.aparc.a2009s.stats',
 'rh.aparc.stats']</code></pre>
</div>
<p><code>aseg</code> files are related to subcortical regions, as we
just saw with <code>aseg.stats</code>, while <code>aparc</code> files
include cortical metrics and are often separated into left
(<code>lh</code>) and right hemisphere (<code>rh</code>).
<code>aparc.stats</code> is for the Desikan-Killiany atlas while
<code>aparc.a2009s.stats</code> is for the Destrieux atlas (148 ROIs vs
68 ROIs for Desikan-Killiany).</p>
<p>Looking at the Destrieux ROI measurements in the left hemisphere from
<code>lh.aparc.a2009s.stats</code> we get:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>n_lines <span class="op">=</span> <span class="dv">75</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(os.path.join(fs_rawstats_dir, <span class="st">"lh.aparc.a2009s.stats"</span>)) <span class="im">as</span> fs_stats_file:</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>    first_n_lines <span class="op">=</span> <span class="bu">list</span>(islice(fs_stats_file, n_lines))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['# Table of FreeSurfer cortical parcellation anatomical statistics \n',
 '# \n',
 '# CreationTime 2019/03/02-22:05:09-GMT\n',
 '# generating_program mris_anatomical_stats\n',
 '# cvs_version $Id: mris_anatomical_stats.c,v 1.79 2016/03/14 15:15:34 greve Exp $\n',
 '# mrisurf.c-cvs_version $Id: mrisurf.c,v 1.781.2.6 2016/12/27 16:47:14 zkaufman Exp $\n',
 '# cmdline mris_anatomical_stats -th3 -mgz -cortex ../label/lh.cortex.label -f ../stats/lh.aparc.a2009s.stats -b -a ../label/lh.aparc.a2009s.annot -c ../label/aparc.annot.a2009s.ctab sub-0001 lh white \n',
 ...
 '# ColHeaders StructName NumVert SurfArea GrayVol ThickAvg ThickStd MeanCurv GausCurv FoldInd CurvInd\n',
 'G&amp;S_frontomargin                         1116    840   1758  1.925 0.540     0.128     0.025       14     1.0\n',
 'G&amp;S_occipital_inf                        1980   1336   3775  2.517 0.517     0.144     0.028       27     2.1\n',
 'G&amp;S_paracentral                          1784   1108   2952  2.266 0.581     0.105     0.018       17     1.3\n',
 ...</code></pre>
</div>
<p>You can see a number of metrics, with more information in the skipped
header on their units. The one of particular interest to us is the
cortical thickness <code>ThickAvg</code>. Since the thickness is
measured at each vertex of the mesh, both the man and standard deviation
can be estimated for each ROI. The values at each vertex is available in
the freesurfer native file <code>lh.thickness</code>. Let’s use it to
plot the values on a mesh.</p>
</div>
<div class="section level4">
<h4 id="plotting-cortical-thickness-values-on-a-subject-mesh">Plotting cortical thickness values on a subject mesh<a class="anchor" aria-label="anchor" href="#plotting-cortical-thickness-values-on-a-subject-mesh"></a>
</h4>
<p>To plot the cortical thickness values on a subject cortical mesh we
will use the native Freesurfer file formats (although the GII file
output by <code>smriprep/fmriprep</code> could also be used as seen in
episode 4). Considering we identified for the left hemispher the path to
the pial mesh <code>lh_pial</code> and the mesh thickness values
<code>lh_thickness</code> (as well as the sulcus mesh
<code>lh_sulcus</code> for a better plot rendering), we can obtain mesh
lateral and medial views with the following Python code:</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="co"># Lateral</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>plotting.plot_surf(lh_pial, surf_map<span class="op">=</span>lh_thickness, hemi<span class="op">=</span><span class="st">'left'</span>, view<span class="op">=</span><span class="st">'lateral'</span>, bg_map<span class="op">=</span>lh_sulcus)<span class="op">;</span></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a><span class="co"># Medial</span></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>plotting.plot_surf(lh_pial, surf_map<span class="op">=</span>lh_thickness, hemi<span class="op">=</span><span class="st">'left'</span>, view<span class="op">=</span><span class="st">'medial'</span>, bg_map<span class="op">=</span>lh_sulcus)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_6/subject_cortical_thickness_mesh.png" alt="Cortical thickness visualization for a given subject" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="generating-and-plotting-summary-group-measurements">Generating and plotting summary group measurements<a class="anchor" aria-label="anchor" href="#generating-and-plotting-summary-group-measurements"></a>
</h4>
<p>Files including metrics for each subject can be leveraged to generate
group results automatically. The first step is to generate more easily
manipulatable CSV/TSV files from the Freesurfer native text files. This
can be done with the Freesurfer <code>asegstats2table</code> command
such as with the code below adapted from <a href="https://github.com/NILAB-UvA/AOMIC-common-scripts/blob/master/fs_stats/create_freesurfer_tables.sh" class="external-link">this
script</a>:</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="va">SUBJECTS</span><span class="op">=</span><span class="va">(</span>...<span class="va">)</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="va">MEASURE</span><span class="op">=</span>thickness</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="va">PARC</span><span class="op">=</span>aparc.a2009s</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="cf">for</span> HEMI <span class="kw">in</span> lh rh<span class="kw">;</span> <span class="cf">do</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>    <span class="bu">echo</span> <span class="st">"Running aparcstats2table with measure </span><span class="va">${MEASURE}</span><span class="st"> and parcellation </span><span class="va">${parc}</span><span class="st"> for hemisphere </span><span class="va">${HEMI}</span><span class="st">"</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>    <span class="ex">aparcstats2table</span> <span class="at">--subjects</span> <span class="va">${SUBJECTS</span><span class="op">[@]</span><span class="va">}</span> <span class="dt">\</span></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a>        <span class="at">--hemi</span> <span class="va">${hemi}</span> <span class="dt">\</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>        <span class="at">--parc</span> <span class="va">${parc}</span> <span class="dt">\</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>        <span class="at">--measure</span> <span class="va">${MEASURE}</span> <span class="dt">\</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>        <span class="at">--tablefile</span> ../derivatives/fs_stats/data-cortical_type-<span class="va">${parc}</span>_measure-<span class="va">${MEASURE}</span>_hemi-<span class="va">${HEMI}</span>.tsv <span class="dt">\</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>        <span class="at">--delimiter</span> <span class="st">'tab'</span>           </span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a><span class="cf">done</span></span></code></pre>
</div>
<p>Then the resulting files can be read with pandas to create a
dataframe including cortical thickness information for all our
subjects.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>hemi<span class="op">=</span><span class="st">"lh"</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>stats_file <span class="op">=</span> os.path.join(fs_stats_dir, </span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>                          <span class="ss">f"data-cortical_type-aparc.a2009s_measure-thickness_hemi-</span><span class="sc">{</span>hemi<span class="sc">}</span><span class="ss">.tsv"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>fs_hemi_df <span class="op">=</span> pd.read_csv(stats_file,sep<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>fs_hemi_df</span></code></pre>
</div>
<p>As shown in the notebook associated with the lesson we can then
create a dataframe <code>fs_df</code> combining both data from both
hemispheres, while also renaming columns to facilitate subsequent
analysis.</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>fs_df</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>participant_id	G_and_S_frontomargin	G_and_S_occipital_inf	G_and_S_paracentral	G_and_S_subcentral	G_and_S_transv_frontopol	G_and_S_cingul_Ant	G_and_S_cingul_Mid_Ant	G_and_S_cingul_Mid_Post	G_cingul_Post_dorsal	...	S_precentral_sup_part	S_suborbital	S_subparietal	S_temporal_inf	S_temporal_sup	S_temporal_transverse	MeanThickness	BrainSegVolNotVent	eTIV	hemi
0	sub-0001	1.925	2.517	2.266	2.636	2.600	2.777	2.606	2.736	2.956	...	2.302	2.417	2.514	2.485	2.462	2.752	2.56319	1235952.0	1.560839e+06	lh
1	sub-0002	2.405	2.340	2.400	2.849	2.724	2.888	2.658	2.493	3.202	...	2.342	3.264	2.619	2.212	2.386	2.772	2.45903	1056970.0	1.115228e+06	lh
2	sub-0003	2.477	2.041	2.255	2.648	2.616	2.855	2.924	2.632	2.984	...	2.276	2.130	2.463	2.519	2.456	2.685	2.53883	945765.0	1.186697e+06	lh
3	sub-0004	2.179	2.137	2.366	2.885	2.736	2.968	2.576	2.593	3.211	...	2.145	2.920	2.790	2.304	2.564	2.771	2.51093	973916.0	9.527770e+05	lh
4	sub-0005	2.483	2.438	2.219	2.832	2.686	3.397	2.985	2.585	3.028	...	2.352	3.598	2.331	2.494	2.665	2.538	2.53830	1089881.0	1.497743e+06	lh
5 rows × 79 columns</code></pre>
</div>
<p>We can then create a boxplot of the mean cortical thickness
distribution in each ROI with <code>seaborn</code>, after first
converting the dataframe from wide to long format:</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>plot_df <span class="op">=</span> fs_df[[<span class="st">"hemi"</span>] <span class="op">+</span> roi_cols]</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="co">## Melt dataframe for easier visualization</span></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>plot_long_df <span class="op">=</span> pd.melt(plot_df, id_vars <span class="op">=</span> [<span class="st">'hemi'</span>], value_vars <span class="op">=</span> roi_cols, </span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>                       var_name <span class="op">=</span><span class="st">'ROI'</span>, value_name <span class="op">=</span><span class="st">'cortical thickness'</span>)</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>plot_long_df</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>	hemi	ROI	cortical thickness
0	lh	G_and_S_frontomargin	1.925
1	lh	G_and_S_frontomargin	2.405
2	lh	G_and_S_frontomargin	2.477
3	lh	G_and_S_frontomargin	2.179
4	lh	G_and_S_frontomargin	2.483
...	...	...	...
33443	rh	S_temporal_transverse	3.006
33444	rh	S_temporal_transverse	2.683
33445	rh	S_temporal_transverse	2.418
33446	rh	S_temporal_transverse	2.105
33447	rh	S_temporal_transverse	2.524
</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>g <span class="op">=</span> sns.catplot(x<span class="op">=</span><span class="st">'cortical thickness'</span>, y<span class="op">=</span><span class="st">'ROI'</span>, hue<span class="op">=</span><span class="st">'hemi'</span>, kind<span class="op">=</span><span class="st">'box'</span>, data<span class="op">=</span>plot_long_df)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/group_cortical_thickness_boxplot.png" alt="Group cortical thickness boxplot" class="figure mx-auto d-block"></figure>
</div>
</div>
</section><section><h2 class="section-heading" id="statistical-analysis-cortical-thickness-analysis-based-on-a-surface-atlas">Statistical analysis: cortical thickness analysis based on a surface
atlas<a class="anchor" aria-label="anchor" href="#statistical-analysis-cortical-thickness-analysis-based-on-a-surface-atlas"></a>
</h2>
<hr class="half-width">
<p>Can we measure cortical thickness changes with age in young adults
?</p>
<p>Now that we have cortical thickness measures, we can try to answer
this question by:</p>
<ul>
<li>adding subject demographic variables (age, sex) which will serve as
predictors</li>
<li>creating and fitting a statistical model: we will use linear
regression model</li>
<li>plotting the results</li>
</ul>
<div class="section level3">
<h3 id="gathering-the-model-predictors">Gathering the model predictors<a class="anchor" aria-label="anchor" href="#gathering-the-model-predictors"></a>
</h3>
<p>Since we are interested in the effect of age, we will collect the
subject demographics information which is readily available from the
BIDS dataset. In addition of the age information, we will use sex as a
covariate.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>subjects_info_withna <span class="op">=</span> bids_layout.get(suffix<span class="op">=</span><span class="st">"participants"</span>, extension<span class="op">=</span><span class="st">".tsv"</span>)[<span class="dv">0</span>].get_df()</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>subjects_info_withna</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>participant_id	age	sex	BMI	handedness	education_category	raven_score	NEO_N	NEO_E	NEO_O	NEO_A	NEO_C
0	sub-0001	25.50	M	21.0	right	academic	33.0	23	40	52	47	32
1	sub-0002	23.25	F	22.0	right	academic	19.0	22	47	34	53	46
2	sub-0003	25.00	F	23.0	right	applied	29.0	26	42	37	48	48
3	sub-0004	20.00	F	18.0	right	academic	24.0	32	42	36	48	52
4	sub-0005	24.75	M	27.0	right	academic	24.0	32	51	41	51	53
...	...	...	...	...	...	...	...	...	...	...	...	...
221	sub-0222	22.00	F	20.0	right	academic	30.0	41	35	51	48	42
222	sub-0223	20.75	F	23.0	left	applied	26.0	33	41	54	36	41
223	sub-0224	21.75	M	20.0	right	academic	34.0	22	45	47	46	46
224	sub-0225	20.25	F	28.0	right	academic	27.0	48	32	43	42	37
225	sub-0226	20.00	M	20.0	right	applied	19.0	28	40	39	42	29</code></pre>
</div>
<div id="jupyter-notebook-challenge-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge-1" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>As the name of our dataframe implies, there may be an issue with the
data. Can you spot it ?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Hint
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>You’ll need to use your <code>pandas</code>-fu for this exercise.
Check for NA (aka missing) values in your <code>pandas</code> dataframe.
You can use the <code>isnull()</code>, <code>any()</code> and
<code>.loc</code> methods for filtering rows.</p>
</div>
</div>
</div>
</div>
<div id="jupyter-notebook-challenge-2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="jupyter-notebook-challenge-2" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>If you spotted the issue in the previous challenge, what would you
propose to solve it ?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">
  Hint
  </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>Data imputation can be applied to appropriate columns, with the
<code>fillna()</code> method. You may be interested in the
<code>.mean()</code> and/our <code>mode()</code> methods to get the mean
and most frequent values.</p>
</div>
</div>
</div>
</div>
<p>Now that we have our predictors, to make subsequent analyses easier
we can merge them with our response/predicted cortical thickness
variable in a single dataframe.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>demo_cols <span class="op">=</span> [<span class="st">"participant_id"</span>, <span class="st">"age"</span>, <span class="st">"sex"</span>]</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>fs_all_df <span class="op">=</span> pd.merge(subjects_info[demo_cols], fs_df, on<span class="op">=</span><span class="st">'participant_id'</span>)</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>fs_all_df</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>	participant_id	age	sex	G_and_S_frontomargin	G_and_S_occipital_inf	G_and_S_paracentral	G_and_S_subcentral	G_and_S_transv_frontopol	G_and_S_cingul_Ant	G_and_S_cingul_Mid_Ant	...	S_precentral_sup_part	S_suborbital	S_subparietal	S_temporal_inf	S_temporal_sup	S_temporal_transverse	MeanThickness	BrainSegVolNotVent	eTIV	hemi
0	sub-0001	25.50	M	1.925	2.517	2.266	2.636	2.600	2.777	2.606	...	2.302	2.417	2.514	2.485	2.462	2.752	2.56319	1235952.0	1.560839e+06	lh
1	sub-0001	25.50	M	2.216	2.408	2.381	2.698	2.530	2.947	2.896	...	2.324	2.273	2.588	2.548	2.465	2.675	2.51412	1235952.0	1.560839e+06	rh
2	sub-0002	23.25	F	2.405	2.340	2.400	2.849	2.724	2.888	2.658	...	2.342	3.264	2.619	2.212	2.386	2.772	2.45903	1056970.0	1.115228e+06	lh
3	sub-0002	23.25	F	2.682	2.454	2.511	2.725	2.874	3.202	3.012	...	2.429	2.664	2.676	2.220	2.291	2.714	2.48075	1056970.0	1.115228e+06	rh
4	sub-0003	25.00	F	2.477	2.041	2.255	2.648	2.616	2.855	2.924	...	2.276	2.130	2.463	2.519	2.456	2.685	2.53883	945765.0	1.186697e+06	lh
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
447	sub-0224	21.75	M	2.076	2.653	2.098	2.307	2.463	2.735	2.602	...	2.136	3.253	2.495	2.309	2.562	2.418	2.41761	1140289.0	1.302062e+06	rh
448	sub-0225	20.25	F	2.513	2.495	2.141	2.492	2.757	2.553	2.238	...	2.304	2.870	2.275	2.481	2.533	2.009	2.43156	1080245.0	1.395822e+06	lh
449	sub-0225	20.25	F	3.061	2.164	2.097	2.462	2.753	3.134	2.786	...	2.174	3.429	2.385	2.378	2.303	2.105	2.41200	1080245.0	1.395822e+06	rh
450	sub-0226	20.00	M	3.010	2.189	2.562	3.142	4.072	3.051	2.292	...	2.375	2.812	2.756	2.524	2.617	2.495	2.62877	1257771.0	1.583713e+06	lh
451	sub-0226	20.00	M	3.851	2.270	2.274	2.610	4.198	3.421	3.007	...	2.371	4.938	2.894	2.663	2.445	2.524	2.63557	1257771.0	1.583713e+06	rh
452 rows × 81 columns</code></pre>
</div>
<p>We can plot the cortical thickness data as a function of age for a
single ROI to have an idea of what we may find when applying our model
on all ROIs. Let’s look for example at the anterior mid-cingulate cortex
(<code>G_and_S_cingul_Mid_Ant</code>).</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>response <span class="op">=</span> <span class="st">'G_and_S_cingul_Mid_Ant'</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>predictor <span class="op">=</span> <span class="st">'age'</span></span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>g <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>predictor, y<span class="op">=</span>response, hue<span class="op">=</span><span class="st">'hemi'</span>, data<span class="op">=</span>plot_df)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/roi_thickness_age.png" alt="Example of cortical thickness variation with age in an ROI" class="figure mx-auto d-block"></figure><p>Interesting ! Let’s investigate more formally a potential association
of cortical thickness with age in young adults.</p>
</div>
<div class="section level3">
<h3 id="creating-and-fitting-a-statistical-model">Creating and fitting a statistical model<a class="anchor" aria-label="anchor" href="#creating-and-fitting-a-statistical-model"></a>
</h3>
<p>We will implement an ordinary least square (OLS) regression model.
Before applying to all ROIs and correcting for multiple comparison,
let’s test it on our previous ROI example.</p>
<p>For this purpose we use the Python <code>statsmodels</code> package.
We can create a model formula
<code>{response} ~ {predictor} + {covariates}</code> (similar to R) and
passing it as an argument to the <code>ols</code> method before fitting
our model. In addition of sex, we will use the total intra-cranial
volume (TIV) as covariate.</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>response <span class="op">=</span> <span class="st">'G_and_S_cingul_Mid_Ant'</span></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>predictor <span class="op">=</span> <span class="st">'age'</span></span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a>hemi <span class="op">=</span> <span class="st">'lh'</span></span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a>hemi_df <span class="op">=</span> fs_all_df[fs_all_df[<span class="st">'hemi'</span>]<span class="op">==</span>hemi]</span>
<span id="cb34-8"><a href="#cb34-8" tabindex="-1"></a>covariates <span class="op">=</span> <span class="st">'eTIV + C(sex)'</span></span>
<span id="cb34-9"><a href="#cb34-9" tabindex="-1"></a><span class="co"># Fit regression model</span></span>
<span id="cb34-10"><a href="#cb34-10" tabindex="-1"></a>results <span class="op">=</span> smf.ols(<span class="ss">f"</span><span class="sc">{</span>response<span class="sc">}</span><span class="ss"> ~ </span><span class="sc">{</span>predictor<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>covariates<span class="sc">}</span><span class="ss">"</span>, data<span class="op">=</span>hemi_df).fit()</span></code></pre>
</div>
<p>we can now look at the results to check for variance explained and
statistical significance.</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>results.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>OLS Regression Results
Dep. Variable:	G_and_S_cingul_Mid_Ant	R-squared:	0.060
Model:	OLS	Adj. R-squared:	0.047
Method:	Least Squares	F-statistic:	4.728
Date:	Thu, 03 Jun 2021	Prob (F-statistic):	0.00322
Time:	02:41:24	Log-Likelihood:	62.682
No. Observations:	226	AIC:	-117.4
Df Residuals:	222	BIC:	-103.7
Df Model:	3		
Covariance Type:	nonrobust		

              coef	    std err	     t	    P&gt;|t|	    [0.025	0.975]
Intercept     3.2906	     0.183	     17.954	  0.000	    2.929	    3.652
C(sex)[T.M]  -0.0097	   0.033	    -0.296	  0.768	   -0.074	    0.055
age          -0.0258	   0.007	    -3.706	  0.000	   -0.040	   -0.012
eTIV          1.612e-08	 7.58e-08	 0.213	    0.832	   -1.33e-07	1.66e-07

Omnibus:	2.038	Durbin-Watson:	2.123
Prob(Omnibus):	0.361	Jarque-Bera (JB):	1.683
Skew:	-0.157	Prob(JB):	0.431
Kurtosis:	3.282	Cond. No.	2.03e+07</code></pre>
</div>
<div id="rapid-statistical-interpretation" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="rapid-statistical-interpretation" class="callout-inner">
<h3 class="callout-title">Rapid statistical interpretation</h3>
<div class="callout-content">
<p>Can you provide one sentence summarizing the results of the OLS model
regarding cortical thickness and age ?</p>
</div>
</div>
</div>
<p>To apply the model to all the ROIs, we use the same code as before
but within a for loop. Note that a custom function
<code>format_ols_results</code> has been created to save the results
from the previous output in a dataframe.</p>
<div class="codewrapper sourceCode" id="cb37">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="co"># OLS result df</span></span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>ols_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>predictor <span class="op">=</span> <span class="st">'age'</span></span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a>covariates <span class="op">=</span> <span class="st">'eTIV + C(sex)'</span></span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a><span class="cf">for</span> hemi <span class="kw">in</span> [<span class="st">'lh'</span>,<span class="st">'rh'</span>]:</span>
<span id="cb37-6"><a href="#cb37-6" tabindex="-1"></a>    hemi_df <span class="op">=</span> fs_all_df[fs_all_df[<span class="st">'hemi'</span>]<span class="op">==</span>hemi]</span>
<span id="cb37-7"><a href="#cb37-7" tabindex="-1"></a>    <span class="cf">for</span> response <span class="kw">in</span> roi_cols:</span>
<span id="cb37-8"><a href="#cb37-8" tabindex="-1"></a>        res <span class="op">=</span> smf.ols(<span class="ss">f"</span><span class="sc">{</span>response<span class="sc">}</span><span class="ss"> ~ </span><span class="sc">{</span>predictor<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>covariates<span class="sc">}</span><span class="ss">"</span>, data<span class="op">=</span>hemi_df).fit()</span>
<span id="cb37-9"><a href="#cb37-9" tabindex="-1"></a>        res_df <span class="op">=</span> format_ols_results(res)</span>
<span id="cb37-10"><a href="#cb37-10" tabindex="-1"></a>        res_df[<span class="st">'response'</span>] <span class="op">=</span> response</span>
<span id="cb37-11"><a href="#cb37-11" tabindex="-1"></a>        res_df[<span class="st">'hemi'</span>] <span class="op">=</span> hemi</span>
<span id="cb37-12"><a href="#cb37-12" tabindex="-1"></a>        ols_df <span class="op">=</span> ols_df.append(res_df)</span>
<span id="cb37-13"><a href="#cb37-13" tabindex="-1"></a>ols_df</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>          index          coef       std err       t  P&gt;|t|        [0.025        0.975]        R2  \
0     Intercept  2.481300e+00  2.210000e-01  11.239  0.000  2.046000e+00  2.916000e+00  0.004184
1   C(sex)[T.M] -7.200000e-03  3.900000e-02  -0.182  0.856 -8.500000e-02  7.100000e-02  0.004184
2           age -7.700000e-03  8.000000e-03  -0.921  0.358 -2.400000e-02  9.000000e-03  0.004184
3          eTIV  1.781000e-08  9.140000e-08   0.195  0.846 -1.620000e-07  1.980000e-07  0.004184
0     Intercept  2.593400e+00  1.650000e-01  15.732  0.000  2.269000e+00  2.918000e+00  0.018302
..          ...           ...           ...     ...    ...           ...           ...       ...
3          eTIV  4.495000e-08  4.820000e-08   0.933  0.352 -5.000000e-08  1.400000e-07  0.075192
0     Intercept  3.044100e+00  2.870000e-01  10.589  0.000  2.478000e+00  3.611000e+00  0.040983
1   C(sex)[T.M] -8.830000e-02  5.100000e-02  -1.718  0.087 -1.900000e-01  1.300000e-02  0.040983
2           age -2.590000e-02  1.100000e-02  -2.370  0.019 -4.700000e-02 -4.000000e-03  0.040983
3          eTIV  1.439000e-07  1.190000e-07   1.210  0.228 -9.050000e-08  3.780000e-07  0.040983  </code></pre>
</div>
<p>We correct the results for multiple comparison with Bonferonni
correction before plotting.</p>
<div class="codewrapper sourceCode" id="cb39">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a>predictors <span class="op">=</span> [<span class="st">'age'</span>]</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>all_rois_df <span class="op">=</span> ols_df[ols_df[<span class="st">'index'</span>].isin(predictors)]</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a><span class="co"># Multiple comparison correction</span></span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a>n_comparisons <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> <span class="bu">len</span>(roi_cols) <span class="co"># 2 hemispheres</span></span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb39-6"><a href="#cb39-6" tabindex="-1"></a>alpha_corr <span class="op">=</span> <span class="fl">0.05</span> <span class="op">/</span> n_comparisons</span>
<span id="cb39-7"><a href="#cb39-7" tabindex="-1"></a><span class="co"># Get significant ROIs and hemis</span></span>
<span id="cb39-8"><a href="#cb39-8" tabindex="-1"></a>sign_rois <span class="op">=</span> all_rois_df[all_rois_df[<span class="st">'P&gt;|t|'</span>] <span class="op">&lt;</span> alpha_corr][<span class="st">'response'</span>].values</span>
<span id="cb39-9"><a href="#cb39-9" tabindex="-1"></a>sign_hemis <span class="op">=</span> all_rois_df[all_rois_df[<span class="st">'P&gt;|t|'</span>] <span class="op">&lt;</span> alpha_corr][<span class="st">'hemi'</span>].values</span>
<span id="cb39-10"><a href="#cb39-10" tabindex="-1"></a><span class="co"># Printing correction properties and results</span></span>
<span id="cb39-11"><a href="#cb39-11" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bonferroni correction with </span><span class="sc">{</span>n_comparisons<span class="sc">}</span><span class="ss"> multiple comparisons"</span>)</span>
<span id="cb39-12"><a href="#cb39-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Using corrected alpha threshold of </span><span class="sc">{</span>alpha_corr<span class="sc">:5.4f}</span><span class="ss">'</span>)</span>
<span id="cb39-13"><a href="#cb39-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Significant ROIs:"</span>)</span>
<span id="cb39-14"><a href="#cb39-14" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(<span class="bu">zip</span>(sign_rois, sign_hemis)))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Bonferroni correction with 148 multiple comparisons
Using corrected alpha threshold of 0.0003
Significant ROIs:
[('G_and_S_cingul_Mid_Ant', 'lh'), ('G_and_S_cingul_Mid_Post', 'lh'), ('G_front_inf_Opercular', 'lh'), ('G_front_middle', 'lh'), ('G_front_sup', 'lh'), ('G_occipital_middle', 'lh'), ('G_temp_sup_G_T_transv', 'lh'), ('S_circular_insula_sup', 'lh'), ('S_front_middle', 'lh'), ('S_front_sup', 'lh'), ('S_parieto_occipital', 'lh'), ('S_precentral_sup_part', 'lh'), ('S_temporal_sup', 'lh'), ('G_and_S_cingul_Mid_Post', 'rh'), ('G_cuneus', 'rh'), ('G_front_inf_Triangul', 'rh'), ('G_front_middle', 'rh'), ('G_front_sup', 'rh'), ('G_pariet_inf_Angular', 'rh'), ('G_precentral', 'rh'), ('G_rectus', 'rh'), ('G_temporal_middle', 'rh'), ('S_circular_insula_sup', 'rh'), ('S_front_sup', 'rh')]</code></pre>
</div>
<p>We plot the p-values on a log scale, indicating both the
non-corrected and corrected alpha level.</p>
<div class="codewrapper sourceCode" id="cb41">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>g <span class="op">=</span> sns.catplot(x<span class="op">=</span><span class="st">'P&gt;|t|'</span>, y<span class="op">=</span><span class="st">'response'</span>, kind<span class="op">=</span><span class="st">'bar'</span>, hue<span class="op">=</span><span class="st">'index'</span>, col<span class="op">=</span><span class="st">'hemi'</span>, data<span class="op">=</span>all_rois_df)</span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a>g.<span class="bu">set</span>(xscale<span class="op">=</span><span class="st">'log'</span>, xlim<span class="op">=</span>(<span class="fl">1e-5</span>,<span class="dv">2</span>))</span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> g.axes.flat:</span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a>    ax.axvline(alpha, ls<span class="op">=</span><span class="st">'--'</span>,c<span class="op">=</span><span class="st">'tomato'</span>)</span>
<span id="cb41-5"><a href="#cb41-5" tabindex="-1"></a>    ax.axvline(alpha_corr, ls<span class="op">=</span><span class="st">'--'</span>,c<span class="op">=</span><span class="st">'darkred'</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/ct_age_pvals.png" alt="Cortical thickness vs age - p values" class="figure mx-auto d-block"></figure><p>And the adjusted R-squared</p>
<div class="codewrapper sourceCode" id="cb42">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a>g <span class="op">=</span> sns.catplot(x<span class="op">=</span><span class="st">'R2_adj'</span>, y<span class="op">=</span><span class="st">'response'</span>, col<span class="op">=</span><span class="st">'hemi'</span>, kind<span class="op">=</span><span class="st">'bar'</span>, data<span class="op">=</span>all_rois_df)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/ct_age_r2.png" alt="Cortical thickness vs age - adjusted R squared" class="figure mx-auto d-block"></figure><p>Finally we can plot the t-scores on a mesh for global brain results
visualization.</p>
<p>First we import the Destrieux mesh and labels from
<code>nilearn</code>.</p>
<div class="codewrapper sourceCode" id="cb43">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="co"># Retrieve both the Destrieux atlas and labels</span></span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>destrieux_atlas <span class="op">=</span> datasets.fetch_atlas_surf_destrieux()</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>parcellation <span class="op">=</span> destrieux_atlas[<span class="st">'map_left'</span>]</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>labels <span class="op">=</span> destrieux_atlas[<span class="st">'labels'</span>]</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a>labels <span class="op">=</span> [l.decode(<span class="st">'utf-8'</span>) <span class="cf">for</span> l <span class="kw">in</span> labels]</span>
<span id="cb43-6"><a href="#cb43-6" tabindex="-1"></a><span class="co"># Retrieve fsaverage5 surface dataset for the plotting background.</span></span>
<span id="cb43-7"><a href="#cb43-7" tabindex="-1"></a>fsaverage <span class="op">=</span> datasets.fetch_surf_fsaverage()</span></code></pre>
</div>
<p>Then we a create a statistical map containing one t-score value for
each ROI of the mesh. Because the ROI labels are not identical between
Freesurfer and <code>nilearn</code>, we use a custom function
<code>map_fs_names_to_nilearn</code> to convert them.</p>
<div class="codewrapper sourceCode" id="cb44">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a><span class="co">### Assign a t-score to each surface atlas ROI</span></span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a>stat_map_lh <span class="op">=</span> np.zeros(parcellation.shape[<span class="dv">0</span>], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb44-3"><a href="#cb44-3" tabindex="-1"></a>nilearn_stats_lh, nilearn_stats_rh <span class="op">=</span> map_fs_names_to_nilearn(all_rois_df, new2old_roinames)</span>
<span id="cb44-4"><a href="#cb44-4" tabindex="-1"></a><span class="co"># For left hemisphere</span></span>
<span id="cb44-5"><a href="#cb44-5" tabindex="-1"></a><span class="cf">for</span> roi, t_stat <span class="kw">in</span> nilearn_stats_lh.items():</span>
<span id="cb44-6"><a href="#cb44-6" tabindex="-1"></a>    stat_labels <span class="op">=</span> np.where(parcellation <span class="op">==</span> labels.index(roi))[<span class="dv">0</span>]</span>
<span id="cb44-7"><a href="#cb44-7" tabindex="-1"></a>    stat_map_lh[stat_labels] <span class="op">=</span> t_stat</span>
<span id="cb44-8"><a href="#cb44-8" tabindex="-1"></a><span class="co"># For right hemisphere</span></span>
<span id="cb44-9"><a href="#cb44-9" tabindex="-1"></a>stat_map_rh <span class="op">=</span> np.zeros(parcellation.shape[<span class="dv">0</span>], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb44-10"><a href="#cb44-10" tabindex="-1"></a><span class="cf">for</span> roi, t_stat <span class="kw">in</span> nilearn_stats_rh.items():</span>
<span id="cb44-11"><a href="#cb44-11" tabindex="-1"></a>    stat_labels <span class="op">=</span> np.where(parcellation <span class="op">==</span> labels.index(roi))[<span class="dv">0</span>]</span>
<span id="cb44-12"><a href="#cb44-12" tabindex="-1"></a>    stat_map_rh[stat_labels] <span class="op">=</span> t_stat</span></code></pre>
</div>
<p>Finally we plot the results with <code>nilearn</code>
<code>plot_surf_roi</code> function.</p>
<div class="codewrapper sourceCode" id="cb45">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="co"># Lateral view of left hemisphere</span></span>
<span id="cb45-2"><a href="#cb45-2" tabindex="-1"></a>plotting.plot_surf_roi(fsaverage[<span class="st">'pial_left'</span>], roi_map<span class="op">=</span>stat_map_lh, hemi<span class="op">=</span><span class="st">'left'</span>, view<span class="op">=</span><span class="st">'lateral'</span>, </span>
<span id="cb45-3"><a href="#cb45-3" tabindex="-1"></a>                       bg_map<span class="op">=</span>fsaverage[<span class="st">'sulc_left'</span>], bg_on_data<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span>
<span id="cb45-4"><a href="#cb45-4" tabindex="-1"></a><span class="co"># Medial view of right hemisphere</span></span>
<span id="cb45-5"><a href="#cb45-5" tabindex="-1"></a>plotting.plot_surf_roi(fsaverage[<span class="st">'pial_right'</span>], roi_map<span class="op">=</span>stat_map_rh, hemi<span class="op">=</span><span class="st">'right'</span>, view<span class="op">=</span><span class="st">'medial'</span>,</span>
<span id="cb45-6"><a href="#cb45-6" tabindex="-1"></a>                       bg_map<span class="op">=</span>fsaverage[<span class="st">'sulc_right'</span>], bg_on_data<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_6/ct_age_tvals_left_hemi.png" alt="Cortical thickness vs age - surface t values on left hemi" class="figure mx-auto d-block"></figure><figure><img src="../fig/episode_6/ct_age_tvals_right_hemi.png" alt="Cortical thickness vs age - surface t values on right hemi" class="figure mx-auto d-block"></figure>
</div>
</section><section><h2 class="section-heading" id="statistical-analysis-local-gm-changes-assessed-with-voxel-based-morphometry-vbm">Statistical analysis: local GM changes assessed with Voxel Based
Morphometry (VBM)<a class="anchor" aria-label="anchor" href="#statistical-analysis-local-gm-changes-assessed-with-voxel-based-morphometry-vbm"></a>
</h2>
<hr class="half-width">
<p>Relying on an atlas to identify and characterize brain changes or/and
group differences is a common practice. While it offers more statistical
power by limiting the comparisons to a limited set of regions, it
introduces bias (the results depend on the choice of atlases) and may
miss out on differences limited to a subregion within ROI. Voxel Based
Morphometry (VBM) is a technique purely data-driven to detect changes at
voxel level.</p>
<p>VBM aims at investigating each voxel independently across a group of
subjects. This is a so called mass-univariate analysis: the analysis is
done voxel by voxel and then multiple comparison correction is applied.
In order to compare a given voxel across subjects, an assumption is that
the voxel is at the same position in the subjects’ brain. This
assumption is met by registering all maps of interest to a template. The
maps investigated are often GM probability maps interpreted as local GM
volume (as in this episode).</p>
<p>The comparaison requires first a correction for the transformation to
the template space (called modulation), and then a mass-univariate
statistical approach. We will examine the VBM workflow step by step. We
will run the steps on a limited subset of 10 sujects from our 226
subjects cohort in a <code>subset</code> directory, while loading the
corresponding cohort pre-computed results in the
<code>all_subjects</code> directory.</p>
<div class="section level3">
<h3 id="vbm-processing">VBM processing<a class="anchor" aria-label="anchor" href="#vbm-processing"></a>
</h3>
<div class="section level4">
<h4 id="template-creation">Template creation<a class="anchor" aria-label="anchor" href="#template-creation"></a>
</h4>
<div id="how-to-create-a-template" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="how-to-create-a-template" class="callout-inner">
<h3 class="callout-title">How to create a template ?</h3>
<div class="callout-content">
<p>We want to create a template on which to align the GM probability
maps of all our subjects. Do you have an idea on how to create this
templa?</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4">
  Hint
  </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p>You can have a look at the outputs generated by
<code>smriprep/fmriprep</code>.</p>
</div>
</div>
</div>
</div>
<p>One answer to the template challenge is to use the probability maps
<code>GM10_probamp_files</code> created in MNI space by
<code>smriprep/fmriprep</code> with the <code>MNI152NLin2009cAsym</code>
template. A simple template can be obtained by averaging all these maps.
Note that it is common to create a symmetric by template by average two
mirror versions. We are not doing this in this episode.</p>
<div class="codewrapper sourceCode" id="cb46">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a><span class="co"># Define subset and cohort dirs</span></span>
<span id="cb46-2"><a href="#cb46-2" tabindex="-1"></a>vbm_subset_dir <span class="op">=</span> os.path.join(vbm_dir, <span class="st">"subset"</span>)</span>
<span id="cb46-3"><a href="#cb46-3" tabindex="-1"></a>vbm_cohort_dir <span class="op">=</span> os.path.join(vbm_dir, <span class="st">"all_subjects"</span>)</span>
<span id="cb46-4"><a href="#cb46-4" tabindex="-1"></a><span class="im">from</span> nilearn.image <span class="im">import</span> concat_imgs, mean_img</span>
<span id="cb46-5"><a href="#cb46-5" tabindex="-1"></a><span class="co"># For demonstration create template for subset</span></span>
<span id="cb46-6"><a href="#cb46-6" tabindex="-1"></a>GM10_probmaps_4D_img <span class="op">=</span> concat_imgs(GM10_probmap_files)</span>
<span id="cb46-7"><a href="#cb46-7" tabindex="-1"></a>GM10_probmap_mean_img <span class="op">=</span> mean_img(GM10_probmaps_4D_img)</span>
<span id="cb46-8"><a href="#cb46-8" tabindex="-1"></a>GM10_probmap_mean_img.to_filename(os.path.join(vbm_dir, <span class="st">"GM10.nii.gz"</span>))</span>
<span id="cb46-9"><a href="#cb46-9" tabindex="-1"></a><span class="co"># For the real application load corresponding template for the cohort</span></span>
<span id="cb46-10"><a href="#cb46-10" tabindex="-1"></a>GM226_probmap_mean_img <span class="op">=</span> nib.load(os.path.join(vbm_cohort_dir, <span class="st">"GM226.nii.gz"</span>))</span></code></pre>
</div>
<p>We will need to register all our subject native probability GM map to
the template. The resulting template is 1mm-resolution but computation
performance is increased if the template has a lower resolution, and our
statistical analysis will require smoothing the data in any case. As a
result we will resample the template to 2mm.</p>
<div class="codewrapper sourceCode" id="cb47">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a><span class="im">from</span> nilearn.datasets <span class="im">import</span> load_mni152_template</span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a><span class="im">from</span> nilearn.image <span class="im">import</span> resample_to_img</span>
<span id="cb47-3"><a href="#cb47-3" tabindex="-1"></a>template <span class="op">=</span> load_mni152_template()</span>
<span id="cb47-4"><a href="#cb47-4" tabindex="-1"></a><span class="co"># Apply to our subset</span></span>
<span id="cb47-5"><a href="#cb47-5" tabindex="-1"></a>GM10_probmap_mean_img_2mm <span class="op">=</span> resample_to_img(GM10_probmap_mean_img, template)</span>
<span id="cb47-6"><a href="#cb47-6" tabindex="-1"></a>GM10_probmap_mean_img_2mm.to_filename(os.path.join(vbm_dir, <span class="st">"GM10_2mm.nii.gz"</span>))</span>
<span id="cb47-7"><a href="#cb47-7" tabindex="-1"></a><span class="co"># Load for the whole cohort</span></span>
<span id="cb47-8"><a href="#cb47-8" tabindex="-1"></a>GM226_probmap_mean_img_2mm <span class="op">=</span> nib.load(os.path.join(vbm_cohort_dir, <span class="st">"GM226_2mm.nii.gz"</span>))</span></code></pre>
</div>
<p>We can plot the results to look at the effect of group size and
resolution on the templates.</p>
<div class="codewrapper sourceCode" id="cb48">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a>n_plots,n_cols  <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span></span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a><span class="co">### Plot 1 mm templates</span></span>
<span id="cb48-3"><a href="#cb48-3" tabindex="-1"></a><span class="co"># Subset 10</span></span>
<span id="cb48-4"><a href="#cb48-4" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">1</span>)</span>
<span id="cb48-5"><a href="#cb48-5" tabindex="-1"></a>plt.imshow(GM10_probmap_mean_img.get_fdata()[:, :, <span class="dv">100</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb48-6"><a href="#cb48-6" tabindex="-1"></a><span class="co"># Cohort 256</span></span>
<span id="cb48-7"><a href="#cb48-7" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">2</span>)</span>
<span id="cb48-8"><a href="#cb48-8" tabindex="-1"></a>plt.imshow(GM226_probmap_mean_img.get_fdata()[:, :, <span class="dv">100</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb48-9"><a href="#cb48-9" tabindex="-1"></a><span class="co">### Plot 2 mm templates</span></span>
<span id="cb48-10"><a href="#cb48-10" tabindex="-1"></a><span class="co"># Subset 10</span></span>
<span id="cb48-11"><a href="#cb48-11" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">3</span>)</span>
<span id="cb48-12"><a href="#cb48-12" tabindex="-1"></a>plt.imshow(GM10_probmap_mean_img_2mm.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb48-13"><a href="#cb48-13" tabindex="-1"></a><span class="co"># Cohort 256</span></span>
<span id="cb48-14"><a href="#cb48-14" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">4</span>)</span>
<span id="cb48-15"><a href="#cb48-15" tabindex="-1"></a>plt.imshow(GM226_probmap_mean_img_2mm.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_template_creation.png" alt="VBM template creation" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="transformation-correction-aka-modulation">Transformation correction, aka modulation<a class="anchor" aria-label="anchor" href="#transformation-correction-aka-modulation"></a>
</h4>
<p>To compare GM values after transformation to the template space, they
need to be modulated. Indeed, if a region in the space the subject
expands when transformed to the template space, the intensity values
must be corrected to account for the actually smaller original volume.
This correction can be performed using the ratio between the template
local volume and the corresponding original local volume. The amount of
transformation is measured in each voxel by the Jacobian determinant J.
So the modulation consists in multiplying or dividing by J according to
how it is defined by the transformation software(template volume / local
volume, or local volume / template volume).</p>
<p>In our case we run the FSL fnirt non-linear transform utility with
the code below.</p>
<div class="codewrapper sourceCode" id="cb49">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="va">NATIVE_GM_MAPS</span><span class="op">=</span><span class="va">(</span>data/derivatives/fmriprep/sub-<span class="pp">*</span>/anat/sub-<span class="pp">+([</span><span class="ss">0</span><span class="pp">-</span><span class="ss">9</span><span class="pp">])</span>_label-GM_probseg.nii.gz<span class="va">)</span></span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a><span class="cf">for</span> GM_MAP <span class="kw">in</span> <span class="va">${NATIVE_GM_MAPS</span><span class="op">[@]</span><span class="va">}</span><span class="kw">;</span> <span class="cf">do</span> </span>
<span id="cb49-3"><a href="#cb49-3" tabindex="-1"></a>    <span class="va">SUBJ_NAME</span><span class="op">=</span><span class="va">${GM_MAP</span><span class="op">%%</span>_label<span class="pp">*</span><span class="va">}</span></span>
<span id="cb49-4"><a href="#cb49-4" tabindex="-1"></a>    <span class="ex">fsl_reg</span> <span class="va">${GM_MAP}</span> GM226_2mm.nii.gz <span class="dt">\</span></span>
<span id="cb49-5"><a href="#cb49-5" tabindex="-1"></a>            data/derivatives/vbm/subset/<span class="va">${SUBJ_NAME}</span>/<span class="va">${SUBJ_NAME}</span>_space-GM226_label-GM_probseg <span class="dt">\</span></span>
<span id="cb49-6"><a href="#cb49-6" tabindex="-1"></a>            <span class="at">-fnirt</span> <span class="st">"--config=GM_2_MNI152GM_2mm.cnf </span><span class="dt">\</span></span>
<span id="cb49-7"><a href="#cb49-7" tabindex="-1"></a><span class="st">            --jout=data/derivatives/vbm/subset/</span><span class="va">${SUBJ_NAME}</span><span class="st">/</span><span class="va">${SUBJ_NAME}</span><span class="st">_J"</span></span>
<span id="cb49-8"><a href="#cb49-8" tabindex="-1"></a><span class="cf">done</span></span></code></pre>
</div>
<p>For FSL the Jacobian determinant output is less than 1 if the
original volume expands when warped to the template, and greater than 1
when it contracts.</p>
<div id="jupyter-notebook-challenge-3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="jupyter-notebook-challenge-3" class="callout-inner">
<h3 class="callout-title">Jupyter notebook challenge</h3>
<div class="callout-content">
<p>Considering the definition of J output by FSL. In place of the
question mark (?), what should be in the code below the mathematical
operator applied to the warped GM map to correct for expansion /
contraction in the notebook code: +, -, * or / ?</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb50">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="cf">for</span> subj_name <span class="kw">in</span> subj_names:</span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>    <span class="co"># Get GM probability map in template space</span></span>
<span id="cb50-3"><a href="#cb50-3" tabindex="-1"></a>    warped_GM_file <span class="op">=</span> os.path.join(subj_dir, <span class="ss">f"</span><span class="sc">{</span>subj_name<span class="sc">}</span><span class="ss">_space-GM226_label-GM_probseg.nii.gz"</span>)</span>
<span id="cb50-4"><a href="#cb50-4" tabindex="-1"></a>    warped_GM <span class="op">=</span> nib.load(warped_GM_file)</span>
<span id="cb50-5"><a href="#cb50-5" tabindex="-1"></a>    <span class="co"># Get scaling factors (trace of Jacobian)</span></span>
<span id="cb50-6"><a href="#cb50-6" tabindex="-1"></a>    J_map_file <span class="op">=</span> os.path.join(subj_dir, <span class="ss">f"</span><span class="sc">{</span>subj_name<span class="sc">}</span><span class="ss">_J.nii.gz"</span>)</span>
<span id="cb50-7"><a href="#cb50-7" tabindex="-1"></a>    J_map <span class="op">=</span> nib.load(J_map_file)</span>
<span id="cb50-8"><a href="#cb50-8" tabindex="-1"></a>    <span class="co"># Compute modulated map</span></span>
<span id="cb50-9"><a href="#cb50-9" tabindex="-1"></a>    modulated_map <span class="op">=</span> math_img(<span class="st">"img1 ? img2"</span>, img1<span class="op">=</span>warped_GM, img2<span class="op">=</span>J_map)</span>
<span id="cb50-10"><a href="#cb50-10" tabindex="-1"></a>    <span class="co"># Save modulated image</span></span>
<span id="cb50-11"><a href="#cb50-11" tabindex="-1"></a>    modulated_map_file <span class="op">=</span> os.path.join(subj_dir, <span class="ss">f"</span><span class="sc">{</span>subj_name<span class="sc">}</span><span class="ss">_space-GM226_label-GM_mod.nii.gz"</span>)</span>
<span id="cb50-12"><a href="#cb50-12" tabindex="-1"></a>    modulated_map.to_filename(modulated_map_file)</span></code></pre>
</div>
<p>We can plot all the intermediary steps leading to the modulated maps
for two subjects of our cohort.</p>
<div class="codewrapper sourceCode" id="cb51">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>subs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="bu">len</span>(subs)</span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a>n_plots, n_cols <span class="op">=</span> <span class="dv">5</span><span class="op">*</span>n_sub, n_sub</span>
<span id="cb51-4"><a href="#cb51-4" tabindex="-1"></a>i_slice_match <span class="op">=</span> {<span class="dv">1</span>: <span class="dv">50</span>, <span class="dv">2</span>: <span class="dv">52</span>}</span>
<span id="cb51-5"><a href="#cb51-5" tabindex="-1"></a><span class="cf">for</span> i_sub, sub <span class="kw">in</span> <span class="bu">enumerate</span>(subs):</span>
<span id="cb51-6"><a href="#cb51-6" tabindex="-1"></a>    <span class="co">### Original image</span></span>
<span id="cb51-7"><a href="#cb51-7" tabindex="-1"></a>    plt.subplot(n_plots, n_cols, (i_sub<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb51-8"><a href="#cb51-8" tabindex="-1"></a>    GM_native_probmap_file <span class="op">=</span> GM_native_probmap_files[sub]</span>
<span id="cb51-9"><a href="#cb51-9" tabindex="-1"></a>    GM_native_probmap <span class="op">=</span> nib.load(GM_native_probmap_file)</span>
<span id="cb51-10"><a href="#cb51-10" tabindex="-1"></a>    GM_native_probmap_2mm <span class="op">=</span> resample_to_img(GM_native_probmap, template)</span>
<span id="cb51-11"><a href="#cb51-11" tabindex="-1"></a>    i_slice <span class="op">=</span> i_slice_match[sub]</span>
<span id="cb51-12"><a href="#cb51-12" tabindex="-1"></a>    plt.imshow(GM_native_probmap_2mm.get_fdata()[:, :, i_slice], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">1.3</span>)</span>
<span id="cb51-13"><a href="#cb51-13" tabindex="-1"></a>    <span class="co">### Template</span></span>
<span id="cb51-14"><a href="#cb51-14" tabindex="-1"></a>    plt.subplot(n_plots, n_cols, (i_sub<span class="op">+</span><span class="dv">1</span>)<span class="op">+</span><span class="dv">1</span><span class="op">*</span>n_sub)</span>
<span id="cb51-15"><a href="#cb51-15" tabindex="-1"></a>    plt.imshow(GM226_probmap_mean_img_2mm.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">1.3</span>)</span>
<span id="cb51-16"><a href="#cb51-16" tabindex="-1"></a>    plt.title(<span class="st">'Template'</span>)</span>
<span id="cb51-17"><a href="#cb51-17" tabindex="-1"></a>    plt.colorbar()<span class="op">;</span></span>
<span id="cb51-18"><a href="#cb51-18" tabindex="-1"></a>    <span class="co"># Jacobian</span></span>
<span id="cb51-19"><a href="#cb51-19" tabindex="-1"></a>    plt.subplot(n_plots, n_cols, (i_sub<span class="op">+</span><span class="dv">1</span>)<span class="op">+</span><span class="dv">2</span><span class="op">*</span>n_sub)</span>
<span id="cb51-20"><a href="#cb51-20" tabindex="-1"></a>    log_ticks <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">0.4</span>, <span class="fl">0.4</span>, <span class="dv">10</span>)</span>
<span id="cb51-21"><a href="#cb51-21" tabindex="-1"></a>    plt.imshow(J_10maps_4D.get_fdata()[:, :, <span class="dv">47</span>, sub], origin<span class="op">=</span><span class="st">"lower"</span>, norm<span class="op">=</span>LogNorm())</span>
<span id="cb51-22"><a href="#cb51-22" tabindex="-1"></a>    <span class="co"># Warped image</span></span>
<span id="cb51-23"><a href="#cb51-23" tabindex="-1"></a>    plt.subplot(n_plots, n_cols, (i_sub<span class="op">+</span><span class="dv">1</span>)<span class="op">+</span><span class="dv">3</span><span class="op">*</span>n_sub)</span>
<span id="cb51-24"><a href="#cb51-24" tabindex="-1"></a>    plt.imshow(warped_10maps_4D.get_fdata()[:, :, <span class="dv">47</span>, sub], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">1.3</span>)</span>
<span id="cb51-25"><a href="#cb51-25" tabindex="-1"></a>    <span class="co"># Subset 10</span></span>
<span id="cb51-26"><a href="#cb51-26" tabindex="-1"></a>    plt.subplot(n_plots, n_cols, (i_sub<span class="op">+</span><span class="dv">1</span>)<span class="op">+</span><span class="dv">4</span><span class="op">*</span>n_sub)</span>
<span id="cb51-27"><a href="#cb51-27" tabindex="-1"></a>    plt.imshow(modulated_10maps_4D.get_fdata()[:, :, <span class="dv">47</span>, sub], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">1.3</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_modulated_maps.png" alt="VBM template creation" class="figure mx-auto d-block"></figure><p>To look at the effect of group size and resolution we can look at the
mean warped images for each combination of group size / resolution.</p>
<div class="codewrapper sourceCode" id="cb52">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a>n_plots, n_cols <span class="op">=</span> <span class="dv">6</span>, <span class="dv">2</span></span>
<span id="cb52-2"><a href="#cb52-2" tabindex="-1"></a><span class="co">### Plot GM warped maps</span></span>
<span id="cb52-3"><a href="#cb52-3" tabindex="-1"></a><span class="co"># Subset 10</span></span>
<span id="cb52-4"><a href="#cb52-4" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">1</span>)</span>
<span id="cb52-5"><a href="#cb52-5" tabindex="-1"></a>plt.imshow(warped_10maps_mean.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-6"><a href="#cb52-6" tabindex="-1"></a><span class="co"># Cohort 256</span></span>
<span id="cb52-7"><a href="#cb52-7" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">2</span>)</span>
<span id="cb52-8"><a href="#cb52-8" tabindex="-1"></a>plt.imshow(warped_226maps_mean.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-9"><a href="#cb52-9" tabindex="-1"></a><span class="co">### Plot Jacobian maps</span></span>
<span id="cb52-10"><a href="#cb52-10" tabindex="-1"></a><span class="co"># Subset 10</span></span>
<span id="cb52-11"><a href="#cb52-11" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">3</span>)</span>
<span id="cb52-12"><a href="#cb52-12" tabindex="-1"></a>plt.imshow(np.log(J_10maps_mean.get_fdata()[:, :, <span class="dv">47</span>]), origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=-</span><span class="fl">0.5</span>, vmax<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb52-13"><a href="#cb52-13" tabindex="-1"></a><span class="co"># Cohort 256</span></span>
<span id="cb52-14"><a href="#cb52-14" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">4</span>)</span>
<span id="cb52-15"><a href="#cb52-15" tabindex="-1"></a>plt.imshow(np.log(J_226maps_mean.get_fdata()[:, :, <span class="dv">47</span>]), origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=-</span><span class="fl">0.5</span>, vmax<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb52-16"><a href="#cb52-16" tabindex="-1"></a><span class="co">### Plot GM modulated maps</span></span>
<span id="cb52-17"><a href="#cb52-17" tabindex="-1"></a><span class="co"># Subset 10</span></span>
<span id="cb52-18"><a href="#cb52-18" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">5</span>)</span>
<span id="cb52-19"><a href="#cb52-19" tabindex="-1"></a>plt.imshow(modulated_10maps_mean.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-20"><a href="#cb52-20" tabindex="-1"></a><span class="co"># Cohort 256</span></span>
<span id="cb52-21"><a href="#cb52-21" tabindex="-1"></a>plt.subplot(n_plots, n_cols, <span class="dv">6</span>)</span>
<span id="cb52-22"><a href="#cb52-22" tabindex="-1"></a>plt.imshow(modulated_226maps_mean.get_fdata()[:, :, <span class="dv">47</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_mean_warped_maps.png" alt="VBM mean warped maps" class="figure mx-auto d-block"></figure>
</div>
<div class="section level4">
<h4 id="creation-of-a-gm-mask">Creation of a GM mask<a class="anchor" aria-label="anchor" href="#creation-of-a-gm-mask"></a>
</h4>
<p>To limit our analysis to GM voxels, a GM mask is useful. We can
create it according to the mean modulated GM maps (or e.g. mean GM
probabilistic maps), and setting a treshold. In our case we choose a
modulation value of at least 0.05 in the group average to be included in
the analysis.</p>
<div class="codewrapper sourceCode" id="cb53">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a>GM_mask <span class="op">=</span> math_img(<span class="st">'img &gt; 0.05'</span>, img<span class="op">=</span>modulated_226maps_mean)</span>
<span id="cb53-2"><a href="#cb53-2" tabindex="-1"></a>GM_mask.to_filename(os.path.join(vbm_dir, <span class="st">"GM226_mask.nii.gz"</span>))</span></code></pre>
</div>
<p>The resulting GM maps cover a large extent of the brain:</p>
<div class="codewrapper sourceCode" id="cb54">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a>plt.imshow(GM_mask.get_fdata()[:, :, <span class="dv">50</span>], origin<span class="op">=</span><span class="st">"lower"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_GM_mask.png" alt="VBM mean warped maps" class="figure mx-auto d-block"></figure><p>Now that we have the modulated GM maps all aligned, we can carry out
the statistical analysis.</p>
</div>
</div>
<div class="section level3">
<h3 id="vbm-statistical-analysis">VBM statistical analysis<a class="anchor" aria-label="anchor" href="#vbm-statistical-analysis"></a>
</h3>
<p>For the VBM statistical analysis, we implement a two-level GLM model.
While it is too long to cover in details in this episode, we can explain
it briefly.</p>
<div class="section level4">
<h4 id="principles">Principles<a class="anchor" aria-label="anchor" href="#principles"></a>
</h4>
<p>Consider a single voxel. The GLM model consists in:</p>
<ol style="list-style-type: decimal">
<li>At subject level, evaluating the beta parameters (aka regression
coefficients) in our model. Our model having:</li>
</ol>
<ul>
<li>Modulated GM as response / predicted variable</li>
<li>Age and sex as predictors (with sex as a covariate)</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>At group level, indicating what is the combination of model
parameters we want to assess for a significant effect. In our case we
just want to look at the age beta paramater value across subjects. It is
signicantly positive ? Significantly negative ? Not significantly
negative or positive ?</li>
</ol>
</div>
<div class="section level4">
<h4 id="design-matrix">Design matrix<a class="anchor" aria-label="anchor" href="#design-matrix"></a>
</h4>
<p>The first step consists in defining a design matrix, this is a matrix
with all our predictors/regressors. In our case this is a column for
age, a column for sex, and for an intercept (a constant value).</p>
<div class="codewrapper sourceCode" id="cb55">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a><span class="co"># For the cohort including all subjects</span></span>
<span id="cb55-2"><a href="#cb55-2" tabindex="-1"></a>design_matrix <span class="op">=</span> subjects_info[[<span class="st">"participant_id"</span>, <span class="st">"age"</span>, <span class="st">"sex"</span>]].set_index(<span class="st">"participant_id"</span>)</span>
<span id="cb55-3"><a href="#cb55-3" tabindex="-1"></a>design_matrix <span class="op">=</span> pd.get_dummies(design_matrix, columns<span class="op">=</span>[<span class="st">"sex"</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb55-4"><a href="#cb55-4" tabindex="-1"></a>design_matrix[<span class="st">"intercept"</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb55-5"><a href="#cb55-5" tabindex="-1"></a>design_matrix</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                  age  sex_M  intercept
participant_id
sub-0001        25.50      1          1
sub-0002        23.25      0          1
sub-0003        25.00      0          1
sub-0004        20.00      0          1
sub-0005        24.75      1          1
...               ...    ...        ...
sub-0222        22.00      0          1
sub-0223        20.75      0          1
sub-0224        21.75      1          1
sub-0225        20.25      0          1
sub-0226        20.00      1          1</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb57">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="co"># For the subset of 10 subjects</span></span>
<span id="cb57-2"><a href="#cb57-2" tabindex="-1"></a>dm10 <span class="op">=</span> design_matrix.iloc[:<span class="dv">10</span>]</span>
<span id="cb57-3"><a href="#cb57-3" tabindex="-1"></a>dm10</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                  age  sex_M  intercept
participant_id
sub-0001        25.50      1          1
sub-0002        23.25      0          1
sub-0003        25.00      0          1
sub-0004        20.00      0          1
sub-0005        24.75      1          1
sub-0006        23.75      1          1
sub-0007        19.25      0          1
sub-0008        21.00      1          1
sub-0009        24.75      0          1
sub-0010        24.75      1          1</code></pre>
</div>
<p>To avoid having noisy data which does not satify the GLM statistical
criteria (gaussianity of residuals) it is common to smooth the input
maps. A smooth operation is included when implement our model next.</p>
</div>
<div class="section level4">
<h4 id="second-level-glm">Second level GLM<a class="anchor" aria-label="anchor" href="#second-level-glm"></a>
</h4>
<p>The second step consists in defining what is the linear combination
of <code>[age_beta_parameter, sex_beta_parameter, intercept]</code> we
want to examine. In our case we want to look only at age, so our linear
combination is simply
<code>1 * age_parameter + 0 * sex_parameter + 0 * intercept</code>. This
is defined by what is called a contrast, which is then
<code>[1, 0, 0]</code> in our case.</p>
<p>These two steps can be implemented with the
<code>SecondLevelModel</code> python object of the <code>nilearn</code>
<code>glm</code> module. We can use the <code>fit</code> method of a
<code>SecondLevelModel</code> object on a design matrix to compute all
the beta parameters for each subject. Then we can call the
<code>compute_contrast</code> method with our contrast to assess if GM
local volume is signicantly associated with age.</p>
<p>For our subset of subjects the corresponding Python code is as
follows:</p>
<div class="codewrapper sourceCode" id="cb59">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a><span class="im">from</span> nilearn.glm.second_level <span class="im">import</span> SecondLevelModel</span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a><span class="co"># First level of the two-level GLM</span></span>
<span id="cb59-4"><a href="#cb59-4" tabindex="-1"></a>level2_glm10 <span class="op">=</span> SecondLevelModel(smoothing_fwhm<span class="op">=</span><span class="fl">3.0</span>, mask_img<span class="op">=</span>GM_mask)</span>
<span id="cb59-5"><a href="#cb59-5" tabindex="-1"></a>level2_glm10.fit(modulated_10map_files, design_matrix<span class="op">=</span>dm10)</span>
<span id="cb59-6"><a href="#cb59-6" tabindex="-1"></a><span class="co"># Second level of the two-level</span></span>
<span id="cb59-7"><a href="#cb59-7" tabindex="-1"></a>contrast <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb59-8"><a href="#cb59-8" tabindex="-1"></a>zmap10 <span class="op">=</span> level2_glm10.compute_contrast(second_level_contrast<span class="op">=</span>contrast, output_type<span class="op">=</span><span class="st">'z_score'</span>)</span></code></pre>
</div>
<p>For the cohort we can simply load the associated z-score map.</p>
<div class="codewrapper sourceCode" id="cb60">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" tabindex="-1"></a>zmap226_file <span class="op">=</span> os.path.join(vbm_dir, <span class="st">"zmap_raw_GM226_age.nii.gz"</span>)</span>
<span id="cb60-2"><a href="#cb60-2" tabindex="-1"></a>zmap226 <span class="op">=</span> nib.load(zmap226_file)</span></code></pre>
</div>
<p>from nilearn.glm import threshold_stats_img from nilearn.reporting
import make_glm_report from nilearn.plotting import plot_stat_map</p>
<p>Finally, do not forget we are looking at a massive collection of
voxels. Because we carry out so many statistical tests (one for each
voxel), it is crucial we correct for multiple comparison. We can do so
with <code>nilearn</code> <code>threshold_stats_img</code> function.</p>
<p>For the subset of subjects</p>
<div class="codewrapper sourceCode" id="cb61">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" tabindex="-1"></a>zmap10_thr, z10thr <span class="op">=</span> threshold_stats_img(zmap10, mask_img<span class="op">=</span>GM_mask, alpha<span class="op">=</span><span class="fl">.05</span>, </span>
<span id="cb61-2"><a href="#cb61-2" tabindex="-1"></a>                                       height_control<span class="op">=</span><span class="st">'fpr'</span>, cluster_threshold<span class="op">=</span><span class="dv">50</span>)</span></code></pre>
</div>
<p>For the whole cohort</p>
<div class="codewrapper sourceCode" id="cb62">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" tabindex="-1"></a>zmap226_file <span class="op">=</span> os.path.join(vbm_dir, <span class="st">"zmap_raw_GM226_age.nii.gz"</span>)</span>
<span id="cb62-2"><a href="#cb62-2" tabindex="-1"></a>zmap226 <span class="op">=</span> nib.load(zmap226_file)</span></code></pre>
</div>
<p>We can visualize the results on the cohort either interactively (with
an arbitrary cluster threshold for visualization):</p>
<div class="codewrapper sourceCode" id="cb63">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" tabindex="-1"></a>zmap226_thr, z226thr <span class="op">=</span> threshold_stats_img(zmap226, mask_img<span class="op">=</span>GM_mask, alpha<span class="op">=</span><span class="fl">.05</span>, </span>
<span id="cb63-2"><a href="#cb63-2" tabindex="-1"></a>                                        height_control<span class="op">=</span><span class="st">'fpr'</span>, cluster_threshold<span class="op">=</span><span class="dv">50</span>)</span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_zmap_cohort_interactive.png" alt="VBM mean warped maps" class="figure mx-auto d-block"></figure><p>Or with a static plot (no cluster threshold)</p>
<div class="codewrapper sourceCode" id="cb64">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" tabindex="-1"></a>plotting.plot_stat_map(zmap226, threshold<span class="op">=</span>zthr, colorbar<span class="op">=</span><span class="va">True</span>, display_mode<span class="op">=</span><span class="st">'z'</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/episode_6/VBM_zmap_cohort_static.png" alt="VBM mean warped maps" class="figure mx-auto d-block"></figure><div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Multiple volumetric and surface metrics exist to characterize brain
structure morphology</li>
<li>Both conventional statistical models and specific neuroimaging
approaches can be used</li>
<li>Caution should be exercised at both data inspection and model
interpretation levels</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="aio-07-Reproducibility"><p>Content from <a href="07-Reproducibility.html">sMRI Analysis: Reproducibility Considerations</a></p>
<hr>
<p>Last updated on 2025-02-26 |

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/episodes/07-Reproducibility.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How sensitive are the findings to your MR pipeline parameters?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand impact of software and atlas choices</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-are-here">You Are Here!<a class="anchor" aria-label="anchor" href="#you-are-here"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/episode_7/Course_flow_7.png" alt="course_flow" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="mr-image-processing-pipeline-selection-choices">MR image processing pipeline selection choices<a class="anchor" aria-label="anchor" href="#mr-image-processing-pipeline-selection-choices"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<p>Compute environment</p>
<ul>
<li>OS / system math libraries</li>
<li>Programming libraries Python / R versions</li>
</ul>
</li>
<li>
<p>Software (algorithms and their versions)</p>
<ul>
<li>Image clean-up</li>
<li>Image normalization</li>
<li>Image quantification</li>
</ul>
</li>
<li>
<p>Quality control</p>
<ul>
<li>Manual protocol specifics</li>
<li>Automatic outlier criteria</li>
</ul>
</li>
<li>
<p>Biological priors</p>
<ul>
<li>Templates</li>
<li>Atlases/parcellations: ROI definitions</li>
</ul>
</li>
</ul></section><section><h2 class="section-heading" id="example-software-analysis">Example software analysis<a class="anchor" aria-label="anchor" href="#example-software-analysis"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="task-compare-cortical-thickness-between-freesurfer-and-civet">Task: compare cortical thickness between FreeSurfer and CIVET<a class="anchor" aria-label="anchor" href="#task-compare-cortical-thickness-between-freesurfer-and-civet"></a>
</h3>
<figure><img src="../fig/episode_7/Reproducibility.png" alt="Drawing" align="middle" width="700px" class="figure mx-auto d-block"></figure><p><em>Note: See <a href="%5Bhttps://academic.oup.com/cercor/article/30/9/5014/5831485%5D" class="external-link">this
article</a> for details on brain plots</em></p>
</div>
</section><section><h2 class="section-heading" id="correlation-between-thickness-measurements">Correlation between thickness measurements:<a class="anchor" aria-label="anchor" href="#correlation-between-thickness-measurements"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="software-freesurfer-v5-1-v5-3-v6-0-civet-2-1-and-ants">Software: FreeSurfer (v5.1, v5.3, v6.0), CIVET (2.1) and ANTs<a class="anchor" aria-label="anchor" href="#software-freesurfer-v5-1-v5-3-v6-0-civet-2-1-and-ants"></a>
</h3>
</div>
<div class="section level3">
<h3 id="parcellation-dkt">Parcellation: DKT<a class="anchor" aria-label="anchor" href="#parcellation-dkt"></a>
</h3>
<figure><img src="../fig/episode_7/CT_compare_software.png" alt="Drawing" align="middle" width="700px" class="figure mx-auto d-block"></figure>
</div>
</section><section><h2 class="section-heading" id="possible-choices-for-freesurfer-parcellations">Possible choices for FreeSurfer parcellations<a class="anchor" aria-label="anchor" href="#possible-choices-for-freesurfer-parcellations"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="different-parcellation-different-results">Different parcellation different results?<a class="anchor" aria-label="anchor" href="#different-parcellation-different-results"></a>
</h3>
</div>
<div class="section level3">
<h3 id="inference-pertaining-to-neuroantomical-differences-andor-prediction-models-based-on-individual-neuroanatomical-feature-sets-can-be-sensitive-to-parcellation-choice-">Inference pertaining to neuroantomical differences and/or prediction
models based on individual neuroanatomical feature sets can be sensitive
to parcellation choice.<a class="anchor" aria-label="anchor" href="#inference-pertaining-to-neuroantomical-differences-andor-prediction-models-based-on-individual-neuroanatomical-feature-sets-can-be-sensitive-to-parcellation-choice-"></a>
</h3>
<figure><img src="../fig/episode_7/FreeSurfer_parcels.jpg" alt="Drawing" align="middle" width="700px" class="figure mx-auto d-block"></figure><p><em>Note: Image adopted from <a href="https://link.springer.com/article/10.1007/s12021-021-09519-6" class="external-link">Madan
2021</a></em></p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>It is crucial to assess biological vs methodological variation in
your findings to avoid reproducibility crisis.</li>
</ul>
</div>
</div>
</div>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/SDC-BIDS-sMRI/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:nikhil.bhagwat@mcgill.ca">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.12" class="external-link">sandpaper (0.16.12)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.6" class="external-link">varnish (1.0.6)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries-incubator.github.io/SDC-BIDS-sMRI/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/SDC-BIDS-sMRI/instructor/aio.html",
  "identifier": "https://carpentries-incubator.github.io/SDC-BIDS-sMRI/instructor/aio.html",
  "dateCreated": "2025-05-13",
  "dateModified": "2025-06-03",
  "datePublished": "2025-06-03"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo --><script>
          var _paq = window._paq = window._paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
          _paq.push(["setDomains", ["*.lessons.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
          _paq.push(["setDoNotTrack", true]);
          _paq.push(["disableCookies"]);
          _paq.push(["trackPageView"]);
          _paq.push(["enableLinkTracking"]);
          (function() {
              var u="https://matomo.carpentries.org/";
              _paq.push(["setTrackerUrl", u+"matomo.php"]);
              _paq.push(["setSiteId", "1"]);
              var d=document, g=d.createElement("script"), s=d.getElementsByTagName("script")[0];
              g.async=true; g.src="https://matomo.carpentries.org/matomo.js"; s.parentNode.insertBefore(g,s);
          })();
        </script><!-- End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

